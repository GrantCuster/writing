(window.webpackJsonp=window.webpackJsonp||[]).push([["df40"],{HKp2:function(e,t,n){(window.__NEXT_P=window.__NEXT_P||[]).push(["/posts/2018-01-22-exploring-recommendation-systems",function(){var e=n("qQhj");return{page:e.default||e}}])},qQhj:function(e,t,n){"use strict";n.r(t),n.d(t,"frontMatter",function(){return i}),n.d(t,"default",function(){return m});var a=n("kOwS"),o=n("qNsG"),r=(n("q1tI"),n("E/Ix")),i={layout:"post",title:"Exploring Recommendation Systems",date:new Date("2018-01-22T00:00:00.000Z"),preview_image:"/images/2018/01/ROC_NMF_tag_loop_1115_nodot.png",author:"Shioulin",author_link:"https://twitter.com/shioulin_sam"},s={frontMatter:i},c="wrapper";function m(e){var t=e.components,n=Object(o.a)(e,["components"]);return Object(r.b)(c,Object(a.a)({},s,n,{components:t,mdxType:"MDXLayout"}),Object(r.b)("p",null,"While we commonly associate recommendation systems with e-commerce, their\napplication extends to any decision-making problem which requires pairing two\ntypes of things together. To understand why recommenders don't always work as\nwell as we'd like them to, we set out to build some basic recommendation systems\nusing publicly available data."),Object(r.b)("h2",null,"Data"),Object(r.b)("p",null,"The first ingredient for building a recommendation system is user interaction\ndata. We experimented with two different datasets, one from Flickr and one from\nAmazon. The Flickr dataset contains interactions between users and photos that\nthey liked; the Amazon dataset contains user ratings on books. Both datasets are\ntime-stamped. The Flickr dataset has positive class data only (i.e. liked\nphotos), while the Amazon dataset has granular ratings data ranging from 1 to 5."),Object(r.b)("p",null,"In general, user interaction data is ",Object(r.b)("em",{parentName:"p"},"sparse,")," since a single user would only\nhave interacted with a small subset of items (think about how many movies you\nhave rated on Netflix). In addition, users tend to rate good items only, leading\nto class imbalance. For datasets with granular ratings data, not only is it hard\nfor a user to differentiate 2 from 3, a 3 could also mean different things to\ndifferent users."),Object(r.b)("p",null,"In recommendation systems, it is important to remove both users who have\ninteracted with many items and items that have many ratings. Intuitively, users\nwho like many items do not add any useful information to our system, as they are\nnot selective enough. Similarly, items that many users like will tend to be\noverly recommended. To clean our dataset, we filtered out these cases. We then\nsplit the dataset into two (training and testing), using a cutoff timestamp."),Object(r.b)("h2",null,"Building the Recommender"),Object(r.b)("p",null,"The goal of a recommendation system is to use historical interaction data to\nrecommend a new pairing (user and item) for the future. There are two\napproaches. The first approach predicts an actual rating for a user-item pair\nand recommends the highest rated item for that user. The second approach\npredicts a ranking of items and recommends the highest ranked item for a\nuser. Our experiment focuses on the first approach. The recommenders are\nevaluated using standard metrics such as area under curve (AUC) and root mean\nsquared error (RMSE)."),Object(r.b)("p",null,"AUC computes the area under the ROC curve for classification problems, and a\nlarger number is better. The\n",Object(r.b)("a",Object(a.a)({parentName:"p"},{href:"https://en.wikipedia.org/wiki/Receiver_operating_characteristic"}),"ROC")," curve\nplots the true positive rate against the false positive rate. We want a\nclassifier that correctly identifies as many positive instances as are available, with\na very low percentage of negative instances incorrectly classified as\npositive. As a result, the ROC curve of a perfect classifier will go straight up\nthe y axis (true positive rate) and then along the x axis (false positive\nrate). A classifier with no power will sit on the x=y diagonal. RMSE computes\nhow far the predicted value is from the actual value."),Object(r.b)("h3",null,"Basic photo recommendation system"),Object(r.b)("p",null,"To quickly get a recommender up and running, we used a Python scikit called\n",Object(r.b)("a",Object(a.a)({parentName:"p"},{href:"https://github.com/NicolasHug/Surprise"}),"SURPRISE"),". The package has various\nbuilt-in recommendation algorithms including ones based on neighborhood approach\nand matrix factorization. Neighborhood approach finds a group of users who are\nsimilar to you and assumes that you share the same item preferences. The\nalgorithm then recommends to you items that these users have liked. Matrix\nfactorization represents users and items using a set of factors and predicts\nuser preference for items using a linear combination of these factors. Because a\nrecommender needs to know both what a user liked and disliked, we used\nheuristics to infer negative ratings for the Flickr dataset. (An example\nheuristic is to assume that ",Object(r.b)("em",{parentName:"p"},"x")," number of photos before the ",Object(r.b)("em",{parentName:"p"},"liked")," photo are\ndisliked.)"),Object(r.b)("p",null,"With both positive and negative ratings, we were ready to plug our data into\nSURPRISE. To do so, we transformed it into a text file that provides four pieces\nof information {userid, photoid, rating, timestamp}, where a rating is either a 1\nor 5."),Object(r.b)("p",null,"The following code snippet shows how custom datasets can be defined and used in\nSURPRISE. "),Object(r.b)("pre",null,Object(r.b)("code",Object(a.a)({parentName:"pre"},{className:"language-python"}),"from surprise import Dataset\nfrom surprise import Reader\n\ntrain_file = os.path.expanduser(data_path + 'train.data')\ntest_file = os.path.expanduser(data_path + 'test.data')\nreader = Reader(line_format='user item rating timestamp', sep=';')\ndata = Dataset.load_from_folds([(train_file, test_file)], reader=reader)\n")),Object(r.b)("p",null,"Training a model and getting a prediction is straightforward."),Object(r.b)("pre",null,Object(r.b)("code",Object(a.a)({parentName:"pre"},{className:"language-python"}),"from surprise import dump\nfrom surprise import KNNBasic\nfrom surprise.accuracy import rmse\n\nalgo = KNNBasic(sim_options=sim_options, min_k=3)\nfor trainset, testset in data.folds():\n    algo.train(trainset)\n    predictions = algo.test(testset)\n    rmse(predictions)\n    dump('./dump_KNN', predictions, trainset, algo)\n")),Object(r.b)("p",null,"The ROC curve for our system was underwhelming - it is very close to the diagonal\nline because there is not enough information in the interaction matrix."),Object(r.b)("p",null,Object(r.b)("img",Object(a.a)({parentName:"p"},{src:"/images/2018/01/ROC_NMF_nodot_1115.png",alt:null}))),Object(r.b)("h3",null,"Photo recommender with Tags"),Object(r.b)("p",null,"Could we build a better recommendation system if we made use of the tag\ninformation that comes for free with the Flickr dataset? Instead of describing a\nphoto using its id (a series of numbers), we used tags like ",Object(r.b)("em",{parentName:"p"},"sunset, bridge,\nBrooklyn"),". Why? First, by doing so, we hoped to add more information to the\ninteraction matrix. Second, our basic photo recommender was unable to recommend\na new photo because it did not have any historical interaction\ninformation. Since it did not know who had interacted with this photo and what\nthe outcome of the interaction was, it did not know how to recommend this new\nitem. (This is known as the ",Object(r.b)("em",{parentName:"p"},"cold start")," problem.) By adding tags, we built\na system that understands the content of what it is recommending. With this\nunderstanding comes the ability to recommend items that it has never seen\nbefore. A new photo is no longer new to the system; it can be represented by a\nset of tags that the system has seen before."),Object(r.b)("p",null,"When we describe a photo with a set of tags, each column of the input matrix is\nnow a tag (vs a photo id). As such, the size of the input matrix becomes much\nlarger. For each user, the recommender returns a set of tags and their\ncorresponding scores. To get back a photo recommendation, these tag scores need\nto be converted to photo scores. For each photo, we compute its score by i)\ncomparing the recommended tags to the set of tags representing the photo, ii)\nfinding the common tags between them, iii) adding up the scores for the common\ntags and iv) normalizing by the number of common tags. All photos are ranked\nusing this score and the top one is recommended. Once tag information is\nincorporated, our ROC curve looked much better!"),Object(r.b)("p",null,Object(r.b)("img",Object(a.a)({parentName:"p"},{src:"/images/2018/01/ROC_NMF_tag_loop_1115_nodot.png",alt:null}))),Object(r.b)("h3",null,"Basic book recommendation system"),Object(r.b)("p",null,"Our recommender based on Flickr's dataset required inferred negative\nratings. Amazon's user rating dataset, on the other hand, provides rating\ninformation ranging from 1 to 5. We tested two recommenders on this dataset: the\nfirst was a recommender we built using Python's scikit-learn package; the second\nwas a recommender put together using\n",Object(r.b)("a",Object(a.a)({parentName:"p"},{href:"https://github.com/maciejkula/spotlight"}),"Spotlight"),", a PyTorch based\nrecommendation package. In our scikit-learn implementation we incorporated both\nmatrix factorization and neighborhood-based algorithms. In the Spotlight\nrecommender, we built an engine using matrix factorization since Spotlight does\nnot support neighborhood based-approaches. All recommenders are evaluated using\nRMSE."),Object(r.b)("p",null,"We cleaned and separated the Amazon dataset into training and testing sets using the same\napproach as we did with the Flickr dataset. From here, we transformed the input data into an\ninteraction matrix for our sklearn-based recommender. Each row in the\ninteraction matrix represents a user and each column represents a book. For\nSpotlight, this interaction matrix is converted into a custom ",Object(r.b)("em",{parentName:"p"},"interactions"),"\nobject. This object takes in three arrays: user ID, book ID, and ratings\ninformation. The user ID is the row index for our interaction matrix, the book\nID is the column index, and the rating information is the value of the\ninteraction matrix. Here is the code snippet. "),Object(r.b)("pre",null,Object(r.b)("code",Object(a.a)({parentName:"pre"},{className:"language-python"}),"from spotlight.interactions import Interactions\ninteractions = Interactions(np.asarray(userid, dtype=np.int32),\n                    np.asarray(bookid, dtype=np.int32),\n                            np.asarray(ratings_all, dtype=np.float32))\n")),Object(r.b)("p",null,"Training and scoring the model is a two liner."),Object(r.b)("pre",null,Object(r.b)("code",Object(a.a)({parentName:"pre"},{className:"language-python"}),"from spotlight.factorization.explicit import ExplicitFactorizationModel\nfrom spotlight.evaluation import rmse_score\n\nmodel = ExplicitFactorizationModel(n_iter=1)\nmodel.fit(sp_train[0])\nrmse = rmse_score(model, sp_test[0])  # 0.62\n")),Object(r.b)("p",null,"Similar to our results with the Flickr dataset, the initial results were underwhelming, but expected for a\nsystem built using only user and book ratings information."),Object(r.b)("h3",null,"Book Recommender with Subject"),Object(r.b)("p",null,"What if we added some content information to the books? In the Flickr dataset,\neach photo already has a set of tags associated with it; content information is\nfree! For the Amazon dataset, we obtained subject information using the open\nlibrary API. This allowed us to identify a book using its subject. Each column in\nour interaction matrix is now a subject rather than a book ID. Since multiple\nbooks can be mapped to the same subject, our input matrix is smaller and\ndenser. (This is in contrast to the Flickr dataset, where adding content\ninformation expanded the input matrix.) Ratings that a user assigned for books\nwith the same subject are aggregated into a single rating for that particular\nsubject. To obtain a recommended rating on a book, we mapped the book to its\nsubject and read off that recommendation. With subject information, the RMSE\nimproved by approximately 2-fold across the board! Unfortunately, we also saw\nthat most of the algorithms do not work since they perform worse than a random\nrecommender when we use RMSE as a metric."),Object(r.b)("table",null,Object(r.b)("thead",{parentName:"table"},Object(r.b)("tr",{parentName:"thead"},Object(r.b)("th",Object(a.a)({parentName:"tr"},{align:"center"}),"Algorithm"),Object(r.b)("th",Object(a.a)({parentName:"tr"},{align:"center"}),"RMSE"))),Object(r.b)("tbody",{parentName:"table"},Object(r.b)("tr",{parentName:"tbody"},Object(r.b)("td",Object(a.a)({parentName:"tr"},{align:"center"}),"NMF (ID)"),Object(r.b)("td",Object(a.a)({parentName:"tr"},{align:"center"}),"0.84")),Object(r.b)("tr",{parentName:"tbody"},Object(r.b)("td",Object(a.a)({parentName:"tr"},{align:"center"}),"NMF (Subject)"),Object(r.b)("td",Object(a.a)({parentName:"tr"},{align:"center"}),"0.46")),Object(r.b)("tr",{parentName:"tbody"},Object(r.b)("td",Object(a.a)({parentName:"tr"},{align:"center"}),"Neighborhood (ID)"),Object(r.b)("td",Object(a.a)({parentName:"tr"},{align:"center"}),"0.84")),Object(r.b)("tr",{parentName:"tbody"},Object(r.b)("td",Object(a.a)({parentName:"tr"},{align:"center"}),"Neighborhood (Subject)"),Object(r.b)("td",Object(a.a)({parentName:"tr"},{align:"center"}),"0.44")),Object(r.b)("tr",{parentName:"tbody"},Object(r.b)("td",Object(a.a)({parentName:"tr"},{align:"center"}),"Spotlight MF (ID)"),Object(r.b)("td",Object(a.a)({parentName:"tr"},{align:"center"}),"0.62")),Object(r.b)("tr",{parentName:"tbody"},Object(r.b)("td",Object(a.a)({parentName:"tr"},{align:"center"}),"Spotlight MF (Subject)"),Object(r.b)("td",Object(a.a)({parentName:"tr"},{align:"center"}),"0.27")),Object(r.b)("tr",{parentName:"tbody"},Object(r.b)("td",Object(a.a)({parentName:"tr"},{align:"center"}),"Random"),Object(r.b)("td",Object(a.a)({parentName:"tr"},{align:"center"}),"0.38")))),Object(r.b)("h2",null,"What we learned"),Object(r.b)("h3",null,"Raw material"),Object(r.b)("p",null,"Data makes all the difference. Traditional recommendation systems do not work\nwell because of the sparsity problem. Each user only rates a small percentage of\nitems in the universe, but recommendation systems rely on this weak signal to\nmake decisions."),Object(r.b)("p",null,"To make a better system we need a denser matrix in order to extract a stronger\nsignal. In our example we used content information: tags for the Flickr dataset\nand subjects for the Amazon dataset. Both cases saw dramatic\nimprovements. "),Object(r.b)("p",null,"Time-stamp information is also helpful because it makes the\nproblem amenable to some deep learning techniques. As an example, the prototype we built to\naccompany our new Semantic Recommendations report uses deep features as a way of\nextending the factorization models."),Object(r.b)("h3",null,"Does a basic recommendation system work?"),Object(r.b)("p",null,"A recommendation system built using matrix factorization or neighborhood\napproaches trained on simple user-item interaction data is unlikely to give\ngreat recommendations. In our experiment with the Amazon dataset, these\nrecommendation systems underperform a random system! Moreover, these systems\nsuffer from the cold start problem - they rely on historical interaction data\nand cannot make recommendations on new items."),Object(r.b)("p",null,"For more on recommendation systems, please see our new report! The Semantic\nRecommendations report explores the current state of recommendation systems,\nwith a focus on how machines can better understand content. Armed with this\nnewfound understanding, we look at how systems can bypass the cold start problem\nand expand their utility well beyond traditional e-commerce use cases."))}m.isMDXComponent=!0}},[["HKp2","5d41","9da1"]]]);