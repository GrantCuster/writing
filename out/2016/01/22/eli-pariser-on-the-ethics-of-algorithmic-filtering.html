<!DOCTYPE html><html><head><link rel="preload" href="/static/fonts/Inter-Regular.woff2?v=3.5" as="font" type="font/woff2" crossorigin="*"/><link rel="preload" href="/static/fonts/Inter-Italic.woff2?v=3.5" as="font" type="font/woff2" crossorigin="*"/><link href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css" rel="stylesheet"/><meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1" class="next-head"/><meta charSet="utf-8" class="next-head"/><style class="next-head">.js-no-flash { display: none }</style><noscript class="jsx-4059783939 jsx-3344216300 next-head"><style>.js-no-flash { display: block }</style></noscript><link rel="icon" type="image/x-icon" href="static/images/favicon.png" class="jsx-1135431938 jsx-2959859206 next-head"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous" class="jsx-1135431938 jsx-2959859206 next-head"/><title class="jsx-1135431938 jsx-2959859206 next-head">Eli Pariser on the Ethics of Algorithmic Filtering - Cloudera Fast Forward</title><link rel="preload" href="/_next/static/EnU~FBvqy_55fWO5RkIyH/pages/posts/2016-01-22-eli-pariser-on-the-ethics-of-algorithmic-filtering.js" as="script"/><link rel="preload" href="/_next/static/EnU~FBvqy_55fWO5RkIyH/pages/_app.js" as="script"/><link rel="preload" href="/_next/static/runtime/webpack-fdce77a122c11e06ae50.js" as="script"/><link rel="preload" href="/_next/static/chunks/commons.f77b50de979bfbbb280b.js" as="script"/><link rel="preload" href="/_next/static/runtime/main-5ab107747766f1b4e0bf.js" as="script"/><style id="__jsx-4059783939">@font-face{font-family:'Inter';font-style:normal;font-weight:400;src:url('/static/fonts/Inter-Regular.woff2?v=3.5') format('woff2'), url('/static/fonts/Inter-Regular.woff?v=3.5') format('woff');}@font-face{font-family:'Inter';font-style:italic;font-weight:400;src:url('/static/fonts/Inter-Italic.woff2?v=3.5') format('woff2'), url('/static/fonts/Inter-Italic.woff?v=3.5') format('woff');}@font-face{font-family:'Inter';font-style:normal;font-weight:700;src:url('/static/fonts/Inter-Bold.woff2?v=3.5') format('woff2'), url('/static/fonts/Inter-Bold.woff?v=3.5') format('woff');}@font-face{font-family:'Inter';font-style:italic;font-weight:700;src:url('/static/fonts/Inter-BoldItalic.woff2?v=3.5') format('woff2'), url('/static/fonts/Inter-BoldItalic.woff?v=3.5') format('woff');}*{box-sizing:border-box;}html{font-family:'Inter',serif;font-size:18px;line-height:27px;text-rendering:optimizelegibility;font-feature-settings:'kern';font-kerning:normal;font-feature-settings:'ss02' 1;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;}pre{-webkit-font-smoothing:auto;-moz-osx-font-smoothing:auto;overflow-x:auto;font-family:SFMono-Regular,Consolas,Liberation Mono,Menlo, Monaco,Courier New,monospace;}body{margin:0;overflow-x:hidden;}a{color:inherit;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:opacity 0.025s linear;transition:opacity 0.025s linear;}a:hover{opacity:0.75;}a.no-hover:hover{opacity:1;}.hover_box_overlay{opacity:0;-webkit-transition:opacity 0.025s linear;transition:opacity 0.025s linear;}.hover_box:hover .hover_box_overlay{opacity:1;}a.gray-backer{-webkit-transition:background 0.05s linear;transition:background 0.05s linear;}a.gray-backer:hover{background:#f3f3f3;}button:focus{outline:#999 auto 3px;}</style><style id="__jsx-3344216300">html{font-size:17.189999999999998px;line-height:25.784999999999997px;}a,.display-link{background-image:linear-gradient( to right, black 100%, transparent 0% );background-position:0em calc(1.07em);background-repeat:repeat-x;background-size:1em 0.07em;}a.no-underline{background-image:none;}a.no-hover{background-image:none;}a.no-hover:hover{background-image:none;opacity:1;}</style><style id="__jsx-2959859206">h1,h2,h3,h4,h5,h6{font-weight:400;font-style:normal;margin:0;}h1{font-size:51.56999999999999px;line-height:1.25;}h2{font-size:34.379999999999995px;line-height:1.25;padding-top:25.784999999999997px;margin-bottom:25.784999999999997px;}h3{font-size:25.784999999999997px;line-height:1.25;padding-top:25.784999999999997px;margin-bottom:25.784999999999997px;}h4{font-size:21.487499999999997px;line-height:1.25;padding-top:0px;margin-bottom:25.784999999999997px;}h5{font-size:12.892499999999998px;line-height:1.4375;margin-bottom:12.892499999999998px;padding-bottom:12.892499999999998px;margin-top:-12.892499999999998px;}p{margin:0 0 25.784999999999997px 0;}ol,ul{margin:0 0 25.784999999999997px 0;padding-left:25.784999999999997px;}blockquote{margin:0 0 25.784999999999997px 25.784999999999997px;}.html-video-holder{margin:0 0 25.784999999999997px 0;}video{max-width:100%;}code{background:#eaeaea;padding-right:3px;padding-left:3px;font-size:0.975em;word-break:break-word;}</style><style id="__jsx-1135431938">code[class*='language-'],pre[class*='language-']{color:black;background:none;font-family:Consolas,Monaco,'Andale Mono','Ubuntu Mono', monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;}pre[class*='language-']::-moz-selection,pre[class*='language-']::-moz-selection,code[class*='language-']::-moz-selection,code[class*='language-']::-moz-selection{text-shadow:none;}pre[class*='language-']::selection,pre[class*='language-']::selection,code[class*='language-']::selection,code[class*='language-']::selection{text-shadow:none;}@media print{code[class*='language-'],pre[class*='language-']{text-shadow:none;}}:not(pre)>code[class*='language-']{white-space:normal;}.token.comment,.token.prolog,.token.doctype,.token.cdata{color:slategray;}.token.punctuation{color:#999;}.namespace{opacity:0.7;}.token.property,.token.tag,.token.boolean,.token.number,.token.constant,.token.symbol,.token.deleted{color:#905;}.token.selector,.token.attr-name,.token.string,.token.char,.token.builtin,.token.inserted{color:#690;}.token.operator,.token.entity,.token.url,.language-css .token.string,.style .token.string{color:#9a6e3a;}.token.atrule,.token.attr-value,.token.keyword{color:#07a;}.token.function,.token.class-name{color:#dd4a68;}.token.regex,.token.important,.token.variable{color:#e90;}.token.important,.token.bold{font-weight:bold;}.token.italic{font-style:italic;}.token.entity{cursor:help;}</style></head><body><div id="__next"><div class="jsx-4059783939 jsx-3344216300 js-no-flash"><div style="padding-bottom:12.892499999999998px"><div style="position:relative"><div style="position:relative;padding:6.446249999999999px 12.892499999999998px 6.446249999999999px 12.892499999999998px;background-image:url(&quot;/static/images/dataline.png&quot;)"><div style="display:flex;justify-content:space-between"><div style="display:flex;align-items:center;height:25.784999999999997px;padding-top:1px"><a href="https://www.cloudera.com/products/fast-forward-labs-research.html" style="display:block;line-height:0" class="no-underline no-hover"><img style="height:12.892499999999998px" src="/static/images/cloudera.png"/></a></div><div style="display:flex;align-items:center;padding-top:1px;font-size:17.189999999999998px;line-height:1.5"><a class="no-underline" href="https://www.cloudera.com/products/fast-forward-labs-research.html" style="color:#333e47;font-size:12.892499999999998px;line-height:1.5">About Us →</a></div></div><div style="position:absolute;left:0;width:100%;height:2px;transform:scaleY(0.60165);transform-origin:center center;background:rgba(0,0,0,0.125);bottom:-1px"></div></div><div style="padding:12.892499999999998px 12.892499999999998px 12.892499999999998px 12.892499999999998px;display:flex;justify-content:space-between;font-size:17.189999999999998px;line-height:1.5"><div style="display:flex;align-items:center"><a class="no-hover no-underline" style="display:flex;align-items:center" href="/"><img style="height:18.75272727272727px;width:18.75272727272727px;margin-right:9.669374999999999px;position:relative;top:-0.5860227272727272px" src="/static/images/ff.png"/><div>Fast Forward Labs </div></a></div><div style="display:flex;align-items:center;height:25.784999999999997px"></div><div style="display:flex"><div style="margin-right:12.892499999999998px"><a href="/">Blog</a></div><div><a href="https://experiments.fastforwardlabs.com">AI Experiments</a></div></div></div><div style="position:absolute;left:0;width:100%;height:2px;transform:scaleY(0.60165);transform-origin:center center;background:black;bottom:-1px"></div></div></div><div class="jsx-1135431938 jsx-2959859206"><div style="position:relative" class="jsx-1135431938 jsx-2959859206"><div style="padding-left:6.446249999999999px;padding-right:6.446249999999999px;padding-top:25.784999999999997px" class="jsx-1135431938 jsx-2959859206"><div class="jsx-1135431938 jsx-2959859206"><div style="display:flex;margin-bottom:12.892499999999998px;width:587.1075px;margin-left:0" class="jsx-1135431938 jsx-2959859206"><div style="width:293.55375px;padding:0px 12.892499999999998px;position:relative;font-size:12.892499999999998px;letter-spacing:0.03em;text-transform:uppercase;line-height:1" class="jsx-1135431938 jsx-2959859206">Jan 06 2016</div><div style="width:293.55375px;padding:0px 12.892499999999998px;position:relative;font-size:12.892499999999998px;letter-spacing:0.03em;text-transform:uppercase;line-height:1" class="jsx-1135431938 jsx-2959859206">interview</div></div><div style="margin-bottom:0" class="jsx-1135431938 jsx-2959859206"><div style="font-size:42.974999999999994px;line-height:1.25;padding:0px 12.892499999999998px;width:587.1075px;margin-left:0" class="jsx-1135431938 jsx-2959859206">Eli Pariser on the Ethics of Algorithmic Filtering</div></div><div style="display:flex;flex-wrap:wrap;width:587.1075px;margin-left:0" class="jsx-1135431938 jsx-2959859206"><div style="padding:12.892499999999998px 12.892499999999998px 0px 12.892499999999998px;width:587.1075px" class="jsx-1135431938 jsx-2959859206"><div class="jsx-1135431938 jsx-2959859206">by<!-- --> <a href="https://twitter.com/HumeKathryn" class="jsx-1135431938 jsx-2959859206">Kathryn</a></div></div><div style="width:587.1075px;padding:25.784999999999997px 12.892499999999998px 25.784999999999997px 12.892499999999998px" class="jsx-1135431938 jsx-2959859206"><p><div style="position:relative"><img src="http://68.media.tumblr.com/3172e6d87c1d99d12058845989f9041f/tumblr_inline_o1bgwg1jOS1ta78fg_540.jpg" style="display:block;margin:0;width:100%"/></div></p><blockquote><p>Chiefly his reflection, of which the portrait / Is the reflection, of which the portrait / Is the reflection once removed. / The glass chose to reflect only what he saw / Which was enough for his purpose: his image / Glazed, embalmed, projected at a 180-degree angle.</p></blockquote><h5>— Parmagiano and John Ashbery - Self-Portrait in a Convex Mirror</h5><p><p>Personalizing experiences and recommendations for consumers is the goal of many data science efforts, so much so that the NYC Media Lab created <a href="http://www.nycmedialab.org/personalizationpalooza-16/">Personalizationpalooza</a> to unite technicians and media leadership around the topic. And while <a href="http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1321962">studies have shown</a> that recommendation algorithms promote happy consumers, it’s questionable that also they promote healthy citizens.<b><br/></b></p><p><a href="http://technosociology.org/">Zeynep Tufecki</a>, for example, recently wrote a <a href="https://medium.com/message/how-facebook-s-tyranny-of-the-like-and-engagement-can-be-an-obstacle-to-an-open-and-connected-dddc03a0d39b#.2tc1yluvx">Medium post </a>explaining how Facebook’s focus on “engagement” as a metric for deciding which content to share on user news feeds can happen “to the detriment of the substantive experiences and interactions” she (and others) wants on Facebook. Zufecki illustrates her point with an instance where users felt morally unable to “like” a video with child refugees surrounded by dead bodies. She argues that the platform needs different mechanisms and metrics to ensure that content worth viewing can compete with the content we’re more apt to “like.” </p><p>Tufecki is not alone in her concerns. In 2011, <a href="https://en.wikipedia.org/wiki/Eli_Pariser">Eli Pariser</a>, CEO of <a href="https://www.upworthy.com/">Upworthy</a>, wrote the first monograph about the risks algorithmic filtering poses to citizenship and society. <a href="http://www.amazon.com/The-Filter-Bubble-Personalized-Changing/dp/0143121235">The Filter Bubble</a> is still worth reading today, as it provides a framework for understanding how filtering algorithms work and what personal, social, and political consequences they may have. It’s critical we understand these tools now that the 2016 election season is in full swing. </p><p>We recently interviewed Pariser to see how his thinking has evolved in light of recent algorithmic progress. Keep reading for highlights. </p><p><b>Upworthy has received a lot of attention for using clickbait to engage readers. While you recently <a href="http://digiday.com/publishers/upworthy-goes-clickbait-free-never-headlines/">pivoted your content strategy</a> (and redesigned your logo), what problem was the site originally trying to solve? </b></p><p>A hallmark of a critic is the ability to point out a problem but not propose a good solution. After publishing <i>The Filter Bubble</i>, I was invited all over to give talks about how personalized media techniques generate hollow models of individuals, generating the risk that people only see banal content as opposed to the more important things they aspire to read to play their part as citizens. I didn’t want to be one of those annoying people who can only point out a problem. I wanted to actually work on a solution. So, I got together with <a href="https://twitter.com/peterkoechley">Peter Koechley</a>, at the time an editor at the Onion, and we decided to collaborate on a project to repurpose the algorithms used to curate and spread highly shareable content on topics people should read to make good decisions and be good citizens. Upworthy was the result. </p><p><b>What’s the new strategy? </b></p><p>We have our own proprietary content management system and collect enormous amounts of data each month on user behavior to track and understand how people engage with content. With storage so cheap and computing so fast, it’s easy for us to collect an enormous amount of data. The hard part is making that data actionable, especially for our creative staff, who are storytellers rather than quants. So our focus is on harvesting behavioral data as insights our writers can use to tell better stories. Think of making writing for the web like standup comedy: you put out a riff, see whether people laugh, and refine it to make more people laugh in the future. </p><p><b>What distinguishes Upworthy from comparable sites? </b></p><p>Our focus on promoting engagement and sharing enables us to write a fraction of stories comparable sites promote. We reach about 100 million people per month with only about 200 stories. Other sites of a similar size and user base generate thousands of pieces of content per month to reach the same audience. </p><p><b>What is the concern about personalization algorithms you addressed in <i>The Filter Bubble</i>?</b></p><p>There is way more information on the internet than any of us could ever read and way more products than we could ever buy. As such, personalization algorithms play an important role, but the problem is that you can end up in an uncanny valley of the self, where the model guiding personalization represents not the full you with all your interests, but only a bad 2-D version of you. Take Netflix as an example. Say you sign up and watch two romantic comedies. You may also love <a href="https://en.wikipedia.org/wiki/Italian_neorealism">Italian neorealism</a>, but the Netflix recommender system will base its representation of what you like on the data it has. This limited representation then gets amplified through future recommendations. I called this a “you loop” in the book. </p><p><b>What are the implications beyond repetitive recommendations? </b></p><p>For one, we can generate a false impression that we have the ability to make informed choices. The core issue with personalization algorithms is that they shape not only what you see, but also what you don’t see. When we do something as minor as watch a movie or buy a product, or as major as vote for president, we must be aware of the fact that, by simply trusting algorithms, we can’t measure the degree to which we base choices on the full set of available options. </p><p><b>Facebook published <a href="http://science.sciencemag.org/content/early/2015/05/06/science.aaa1160">an article in Science</a> in May 2015 that drew a large critical response from the community, including critiques <a href="https://medium.com/message/how-facebook-s-algorithm-suppresses-content-diversity-modestly-how-the-newsfeed-rules-the-clicks-b5f8a4bb7bab#.mdbpf9ese">from Zeynep Tufecki</a> and <a href="http://socialmediacollective.org/2015/05/07/the-facebook-its-not-our-fault-study/">Christian Sandvig</a>. The Facebook article argued that, “compared to algorithmic ranking, individuals’ choices about what to consume had a stronger effect limiting exposure” to content with opinions against a user’s stated ideological affiliations. Where do you stand on that? </b></p><p>I agree with Tufecki that personal choice compounds rather than exculpates algorithmic filtering. Sure, beliefs influence what people are interested in, and, in turn, what they click on; but you have to be a very determined reader to dig beyond the limited range of options presented by the tools. The result is that most of us are then exposed to a doubly small range of content. It’s our right as consumers to ask ourselves how much agency we want to make choices about what we see and don’t see.</p></p><p><div style="position:relative"><img src="http://68.media.tumblr.com/8b0eed9f48ab3ce0af98771d4af82110/tumblr_inline_o1bh39RVdG1ta78fg_540.png" style="display:block;margin:0;width:100%"/></div></p><h5>A chart from the appendix of the Facebook report, showing that the higher an item is in the newsfeed, the more likely it is clicked on.</h5><p><p><b>If personalization risks exacerbating political polarization, where can constructive cross-partisan exchange occur online?</b></p><p>One of my favorite discoveries while researching <i>The Filter Bubble</i> was that constructive cross-partisan conversations occurred in two unlikely places: message boards for sports teams and fan space for the television series <i>Lost</i>. The fact that people shared something in common, e.g., they were all Giants fans, created a trusted space for open disagreement about race, class, and other delicate social issues. When united by a common reference point, people are more apt to engage with ideas than in an adversarial, debate-focused context.  </p><p><b>What can technologists do to address issues created by algorithmic filtering? </b></p><p>There are two main things: 1) accepting that behavioral signals are insufficient to explain a person, and working to increase our understanding of human psychology, and; 2) building recommendation systems that try to account for people’s aspirational desires as well as their current behavior. That people click more frequently on celebrity stories than political essays does not mean they don’t want to learn about what’s going on in world. One thing that’s interesting about Facebook’s models of the self, versus Google’s model of the self, is that our Facebook identities are somewhat aspirational. Some dismiss our socially-doctored self as inauthentic. I like to celebrate it as aspirational. </p><p><b>What can consumers do to escape algorithmic filter bubbles? </b></p><p><a href="http://www.marshallmcluhan.com/">Marshall McLuha</a>n was prescient (side note: we love this classic <a href="https://www.youtube.com/watch?v=9wWUc8BZgWE">Annie Hall scene</a>). The first step is for consumers is to become more conscious about the interplay between the medium and message, to accept that our actions on popular websites shape what future stories we’ll see and won’t see. Only then can we learn the basic algorithmic rules and use them to our advantage. In the 70s and 80s, a generation of people figured out how news editors think and why certain stories made first-page headlines to the exclusion of others. Our generation’s task is to understand how people writing algorithms think and what metrics they’re using to promote one story over another. And then, to make the effort to read things of less interest to our present self than to the future self we aspire to become. </p><p>(For those interested in art history and early modern optics, <a href="https://www.youtube.com/watch?v=CS_HUWs9c8c">Tim’s Vermeer</a> is a fantastic study of the techniques Vermeer may have used to create his works.)</p><p>- Kathryn </p></p><div style="display:none;justify-content:center;padding:12.892499999999998px" class="jsx-1135431938 jsx-2959859206"><img style="height:18.75272727272727px;width:18.75272727272727px;position:relative;display:block" src="/static/images/ff.png" class="jsx-1135431938 jsx-2959859206"/></div></div></div></div><div style="position:relative;display:block;width:612.8924999999999px;grid-template-columns:repeat(2, 1fr);margin-left:-12.892499999999998px;margin-right:-12.892499999999998px"><div style="display:grid"><div style="position:relative;display:grid;grid-template-rows:auto 1fr;margin-bottom:12.892499999999998px"><div style="text-transform:uppercase;font-size:12.892499999999998px;letter-spacing:0.03em;line-height:1.5;padding-bottom:6.446249999999999px;padding-left:25.784999999999997px">Newer</div><div style="position:relative;display:grid"><a class="hover-box no-underline no-hover gray-backer hover-extend" style="display:block;position:relative;width:612.8925px;padding-left:12.892499999999998px;padding-right:12.892499999999998px;margin-left:0;margin-right:0" href="/2016/01/27/discussing-nlg-with-automated-insights.html"><div style="display:flex;flex-wrap:wrap"><div style="display:flex;width:587.1075px;font-size:12.892499999999998px;letter-spacing:0.03em;text-transform:uppercase;line-height:1.5;margin-left:0"><div style="width:293.55375px;padding:12.892499999999998px 12.892499999999998px 0px 12.892499999999998px"><div>Jan 04 2016</div></div><div style="width:293.55375px;padding:12.892499999999998px 12.892499999999998px 0px 12.892499999999998px"><div>post</div></div></div><div style="position:relative;width:587.1075px;padding:12.892499999999998px 0px"><div style="font-size:25.784999999999997px;line-height:1.25;padding:0px 12.892499999999998px;margin-top:-6.446249999999999px"><div style="padding-left:0">Discussing NLG with Automated Insights</div></div><div style="padding-top:6.446249999999999px;position:relative"><div style="font-size:15.041249999999998px;line-height:1.5em;display:flex;flex-wrap:wrap;padding-left:0"><div style="padding:0px 12.892499999999998px;width:293.55375px"><div style="height:90.24749999999999px;overflow:hidden;display:-webkit-box;-webkit-line-clamp:4;hyphens:auto;-webkit-box-orient:vertical">

On January 26, we co-hosted an online discussion with Robbie Allen, the founder and CEO of natural language generation software provider Automated Insights. You may know them as the company behind Yahoo! fantasy football reports and the Associated Press’s automated company...</div><div style="overflow:hidden;width:100%;text-overflow:ellipsis;white-space:nowrap"><span class="display-link"><span>View<!-- --> <span style="text-transform:lowercase">post</span></span></span></div></div><div style="position:relative;width:293.55375px"><div style="width:calc(100% - 25.784999999999997px);height:calc(100% - 12.892499999999998px);margin-left:12.892499999999998px;margin-top:6.446249999999999px;background-image:url(http://imgur.com/PihF0QE.png);background-size:contain;background-position:center center;background-repeat:no-repeat"></div></div></div></div></div></div></a><div style="position:absolute;left:-1px;top:-1px;height:calc(158.7301587301587% + 2px);width:calc(158.7301587301587% + 2px);transform:scale(0.6300000000000001);transform-origin:left top;border:solid 2px black;pointer-events:none"></div></div></div></div><div style="display:grid"><div style="position:relative;display:grid;grid-template-rows:auto 1fr;margin-bottom:12.892499999999998px"><div style="text-transform:uppercase;font-size:12.892499999999998px;letter-spacing:0.03em;line-height:1.5;padding-bottom:6.446249999999999px;padding-left:25.784999999999997px">Older</div><div style="position:relative;display:grid"><a class="hover-box no-underline no-hover gray-backer hover-extend" style="display:block;position:relative;width:612.8925px;padding-left:12.892499999999998px;padding-right:12.892499999999998px;margin-left:0;margin-right:0" href="/2016/01/15/demystifying-machine-intelligence.html"><div style="display:flex;flex-wrap:wrap"><div style="display:flex;width:587.1075px;font-size:12.892499999999998px;letter-spacing:0.03em;text-transform:uppercase;line-height:1.5;margin-left:0"><div style="width:293.55375px;padding:12.892499999999998px 12.892499999999998px 0px 12.892499999999998px"><div>Jan 06 2016</div></div><div style="width:293.55375px;padding:12.892499999999998px 12.892499999999998px 0px 12.892499999999998px"><div>post</div></div></div><div style="position:relative;width:587.1075px;padding:12.892499999999998px 0px"><div style="font-size:25.784999999999997px;line-height:1.25;padding:0px 12.892499999999998px;margin-top:-6.446249999999999px"><div style="padding-left:0">Demystifying Machine Intelligence</div></div><div style="padding-top:6.446249999999999px;position:relative"><div style="font-size:15.041249999999998px;line-height:1.5em;display:flex;flex-wrap:wrap;padding-left:0"><div style="padding:0px 12.892499999999998px;width:293.55375px"><div style="height:90.24749999999999px;overflow:hidden;display:-webkit-box;-webkit-line-clamp:4;hyphens:auto;-webkit-box-orient:vertical">

We recently co-hosted an event at 1871 in Chicago with Kris Hammond, Chief Scientist at Narrative Science. Called “Technology Explained,” the event helped attendees understand why machine intelligence is succeeding today and how businesses can leverage new technologies to make...</div><div style="overflow:hidden;width:100%;text-overflow:ellipsis;white-space:nowrap"><span class="display-link"><span>View<!-- --> <span style="text-transform:lowercase">post</span></span></span></div></div><div style="position:relative;width:293.55375px"><div style="width:calc(100% - 25.784999999999997px);height:calc(100% - 12.892499999999998px);margin-left:12.892499999999998px;margin-top:6.446249999999999px;background-image:url(http://imgur.com/fkb8Q7u.png);background-size:contain;background-position:center center;background-repeat:no-repeat"></div></div></div></div></div></div></a><div style="position:absolute;left:-1px;top:-1px;height:calc(158.7301587301587% + 2px);width:calc(158.7301587301587% + 2px);transform:scale(0.6300000000000001);transform-origin:left top;border:solid 2px black;pointer-events:none"></div></div></div></div></div><div style="padding-bottom:25.784999999999997px;padding-top:25.784999999999997px" class="jsx-1135431938 jsx-2959859206"><div style="font-size:34.379999999999995px;line-height:1.25;padding:0px 12.892499999999998px 0px 12.892499999999998px;margin-bottom:12.892499999999998px;width:587.1075px;margin-left:0" class="jsx-1135431938 jsx-2959859206">About</div><div style="padding:0px 12.892499999999998px;margin-bottom:12.892499999999998px;width:587.1075px;margin-left:0;font-size:17.189999999999998px;line-height:1.5" class="jsx-1135431938 jsx-2959859206">Cloudera Fast Forward Labs is an applied machine learning research group. We help organizations recognize and develop new product and business opportunities through emerging technologies.<!-- --> </div><div style="padding:0px 12.892499999999998px;margin-bottom:12.892499999999998px;width:587.1075px;margin-left:0;font-size:17.189999999999998px;line-height:1.5" class="jsx-1135431938 jsx-2959859206"><a href="https://www.cloudera.com/products/fast-forward-labs-research.html" class="jsx-1135431938 jsx-2959859206">Learn more about working with us.</a></div></div></div><div class="jsx-1135431938 jsx-2959859206"><div style="position:relative" class="jsx-1135431938 jsx-2959859206"><div style="position:absolute;left:0;width:100%;height:2px;transform:scaleY(0.60165);transform-origin:center center;background:black;top:-1px"></div><div style="padding:12.892499999999998px;display:flex;justify-content:space-between;flex-wrap:wrap;font-size:17.189999999999998px;line-height:1.5" class="jsx-1135431938 jsx-2959859206"><div class="jsx-1135431938 jsx-2959859206"><a href="/" class="jsx-1135431938 jsx-2959859206">Blog</a></div><div style="display:flex;flex-wrap:wrap" class="jsx-1135431938 jsx-2959859206"><div style="margin-right:12.892499999999998px" class="jsx-1135431938 jsx-2959859206"><a href="https://www.cloudera.com/products/fast-forward-labs-research.html" class="jsx-1135431938 jsx-2959859206">Cloudera</a></div><div style="margin-right:12.892499999999998px" class="jsx-1135431938 jsx-2959859206"><a href="https://blog.fastforwardlabs.com/" class="jsx-1135431938 jsx-2959859206">AI Experiments</a></div><div class="jsx-1135431938 jsx-2959859206"><a href="https://twitter.com/fastforwardlabs" class="jsx-1135431938 jsx-2959859206">Twitter</a></div></div></div></div></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{}},"page":"/posts/2016-01-22-eli-pariser-on-the-ethics-of-algorithmic-filtering","query":{},"buildId":"EnU~FBvqy_55fWO5RkIyH","nextExport":true}</script><script async="" id="__NEXT_PAGE__/posts/2016-01-22-eli-pariser-on-the-ethics-of-algorithmic-filtering" src="/_next/static/EnU~FBvqy_55fWO5RkIyH/pages/posts/2016-01-22-eli-pariser-on-the-ethics-of-algorithmic-filtering.js"></script><script async="" id="__NEXT_PAGE__/_app" src="/_next/static/EnU~FBvqy_55fWO5RkIyH/pages/_app.js"></script><script src="/_next/static/runtime/webpack-fdce77a122c11e06ae50.js" async=""></script><script src="/_next/static/chunks/commons.f77b50de979bfbbb280b.js" async=""></script><script src="/_next/static/runtime/main-5ab107747766f1b4e0bf.js" async=""></script></body></html>