<!DOCTYPE html><html><head><link rel="preload" href="/static/fonts/Inter-Regular.woff2?v=3.5" as="font" type="font/woff2" crossorigin="*"/><link rel="preload" href="/static/fonts/Inter-Italic.woff2?v=3.5" as="font" type="font/woff2" crossorigin="*"/><link href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css" rel="stylesheet"/><meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1" class="next-head"/><meta charSet="utf-8" class="next-head"/><style class="next-head">.js-no-flash { display: none }</style><noscript class="jsx-4059783939 jsx-3344216300 next-head"><style>.js-no-flash { display: block }</style></noscript><link rel="icon" type="image/x-icon" href="static/images/favicon.png" class="jsx-1135431938 jsx-2959859206 next-head"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous" class="jsx-1135431938 jsx-2959859206 next-head"/><title class="jsx-1135431938 jsx-2959859206 next-head">Why your relationship is likely to last (or not): using Local Interpretable Model-Agnostic Explanations (LIME) - Cloudera Fast Forward</title><link rel="preload" href="/_next/static/EnU~FBvqy_55fWO5RkIyH/pages/posts/2017-09-01-LIME-for-couples.js" as="script"/><link rel="preload" href="/_next/static/EnU~FBvqy_55fWO5RkIyH/pages/_app.js" as="script"/><link rel="preload" href="/_next/static/runtime/webpack-fdce77a122c11e06ae50.js" as="script"/><link rel="preload" href="/_next/static/chunks/commons.f77b50de979bfbbb280b.js" as="script"/><link rel="preload" href="/_next/static/runtime/main-5ab107747766f1b4e0bf.js" as="script"/><style id="__jsx-4059783939">@font-face{font-family:'Inter';font-style:normal;font-weight:400;src:url('/static/fonts/Inter-Regular.woff2?v=3.5') format('woff2'), url('/static/fonts/Inter-Regular.woff?v=3.5') format('woff');}@font-face{font-family:'Inter';font-style:italic;font-weight:400;src:url('/static/fonts/Inter-Italic.woff2?v=3.5') format('woff2'), url('/static/fonts/Inter-Italic.woff?v=3.5') format('woff');}@font-face{font-family:'Inter';font-style:normal;font-weight:700;src:url('/static/fonts/Inter-Bold.woff2?v=3.5') format('woff2'), url('/static/fonts/Inter-Bold.woff?v=3.5') format('woff');}@font-face{font-family:'Inter';font-style:italic;font-weight:700;src:url('/static/fonts/Inter-BoldItalic.woff2?v=3.5') format('woff2'), url('/static/fonts/Inter-BoldItalic.woff?v=3.5') format('woff');}*{box-sizing:border-box;}html{font-family:'Inter',serif;font-size:18px;line-height:27px;text-rendering:optimizelegibility;font-feature-settings:'kern';font-kerning:normal;font-feature-settings:'ss02' 1;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;}pre{-webkit-font-smoothing:auto;-moz-osx-font-smoothing:auto;overflow-x:auto;font-family:SFMono-Regular,Consolas,Liberation Mono,Menlo, Monaco,Courier New,monospace;}body{margin:0;overflow-x:hidden;}a{color:inherit;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:opacity 0.025s linear;transition:opacity 0.025s linear;}a:hover{opacity:0.75;}a.no-hover:hover{opacity:1;}.hover_box_overlay{opacity:0;-webkit-transition:opacity 0.025s linear;transition:opacity 0.025s linear;}.hover_box:hover .hover_box_overlay{opacity:1;}a.gray-backer{-webkit-transition:background 0.05s linear;transition:background 0.05s linear;}a.gray-backer:hover{background:#f3f3f3;}button:focus{outline:#999 auto 3px;}</style><style id="__jsx-3344216300">html{font-size:17.189999999999998px;line-height:25.784999999999997px;}a,.display-link{background-image:linear-gradient( to right, black 100%, transparent 0% );background-position:0em calc(1.07em);background-repeat:repeat-x;background-size:1em 0.07em;}a.no-underline{background-image:none;}a.no-hover{background-image:none;}a.no-hover:hover{background-image:none;opacity:1;}</style><style id="__jsx-2959859206">h1,h2,h3,h4,h5,h6{font-weight:400;font-style:normal;margin:0;}h1{font-size:51.56999999999999px;line-height:1.25;}h2{font-size:34.379999999999995px;line-height:1.25;padding-top:25.784999999999997px;margin-bottom:25.784999999999997px;}h3{font-size:25.784999999999997px;line-height:1.25;padding-top:25.784999999999997px;margin-bottom:25.784999999999997px;}h4{font-size:21.487499999999997px;line-height:1.25;padding-top:0px;margin-bottom:25.784999999999997px;}h5{font-size:12.892499999999998px;line-height:1.4375;margin-bottom:12.892499999999998px;padding-bottom:12.892499999999998px;margin-top:-12.892499999999998px;}p{margin:0 0 25.784999999999997px 0;}ol,ul{margin:0 0 25.784999999999997px 0;padding-left:25.784999999999997px;}blockquote{margin:0 0 25.784999999999997px 25.784999999999997px;}.html-video-holder{margin:0 0 25.784999999999997px 0;}video{max-width:100%;}code{background:#eaeaea;padding-right:3px;padding-left:3px;font-size:0.975em;word-break:break-word;}</style><style id="__jsx-1135431938">code[class*='language-'],pre[class*='language-']{color:black;background:none;font-family:Consolas,Monaco,'Andale Mono','Ubuntu Mono', monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;}pre[class*='language-']::-moz-selection,pre[class*='language-']::-moz-selection,code[class*='language-']::-moz-selection,code[class*='language-']::-moz-selection{text-shadow:none;}pre[class*='language-']::selection,pre[class*='language-']::selection,code[class*='language-']::selection,code[class*='language-']::selection{text-shadow:none;}@media print{code[class*='language-'],pre[class*='language-']{text-shadow:none;}}:not(pre)>code[class*='language-']{white-space:normal;}.token.comment,.token.prolog,.token.doctype,.token.cdata{color:slategray;}.token.punctuation{color:#999;}.namespace{opacity:0.7;}.token.property,.token.tag,.token.boolean,.token.number,.token.constant,.token.symbol,.token.deleted{color:#905;}.token.selector,.token.attr-name,.token.string,.token.char,.token.builtin,.token.inserted{color:#690;}.token.operator,.token.entity,.token.url,.language-css .token.string,.style .token.string{color:#9a6e3a;}.token.atrule,.token.attr-value,.token.keyword{color:#07a;}.token.function,.token.class-name{color:#dd4a68;}.token.regex,.token.important,.token.variable{color:#e90;}.token.important,.token.bold{font-weight:bold;}.token.italic{font-style:italic;}.token.entity{cursor:help;}</style></head><body><div id="__next"><div class="jsx-4059783939 jsx-3344216300 js-no-flash"><div style="padding-bottom:12.892499999999998px"><div style="position:relative"><div style="position:relative;padding:6.446249999999999px 12.892499999999998px 6.446249999999999px 12.892499999999998px;background-image:url(&quot;/static/images/dataline.png&quot;)"><div style="display:flex;justify-content:space-between"><div style="display:flex;align-items:center;height:25.784999999999997px;padding-top:1px"><a href="https://www.cloudera.com/products/fast-forward-labs-research.html" style="display:block;line-height:0" class="no-underline no-hover"><img style="height:12.892499999999998px" src="/static/images/cloudera.png"/></a></div><div style="display:flex;align-items:center;padding-top:1px;font-size:17.189999999999998px;line-height:1.5"><a class="no-underline" href="https://www.cloudera.com/products/fast-forward-labs-research.html" style="color:#333e47;font-size:12.892499999999998px;line-height:1.5">About Us →</a></div></div><div style="position:absolute;left:0;width:100%;height:2px;transform:scaleY(0.60165);transform-origin:center center;background:rgba(0,0,0,0.125);bottom:-1px"></div></div><div style="padding:12.892499999999998px 12.892499999999998px 12.892499999999998px 12.892499999999998px;display:flex;justify-content:space-between;font-size:17.189999999999998px;line-height:1.5"><div style="display:flex;align-items:center"><a class="no-hover no-underline" style="display:flex;align-items:center" href="/"><img style="height:18.75272727272727px;width:18.75272727272727px;margin-right:9.669374999999999px;position:relative;top:-0.5860227272727272px" src="/static/images/ff.png"/><div>Fast Forward Labs </div></a></div><div style="display:flex;align-items:center;height:25.784999999999997px"></div><div style="display:flex"><div style="margin-right:12.892499999999998px"><a href="/">Blog</a></div><div><a href="https://experiments.fastforwardlabs.com">AI Experiments</a></div></div></div><div style="position:absolute;left:0;width:100%;height:2px;transform:scaleY(0.60165);transform-origin:center center;background:black;bottom:-1px"></div></div></div><div class="jsx-1135431938 jsx-2959859206"><div style="position:relative" class="jsx-1135431938 jsx-2959859206"><div style="padding-left:6.446249999999999px;padding-right:6.446249999999999px;padding-top:25.784999999999997px" class="jsx-1135431938 jsx-2959859206"><div class="jsx-1135431938 jsx-2959859206"><div style="display:flex;margin-bottom:12.892499999999998px;width:587.1075px;margin-left:0" class="jsx-1135431938 jsx-2959859206"><div style="width:293.55375px;padding:0px 12.892499999999998px;position:relative;font-size:12.892499999999998px;letter-spacing:0.03em;text-transform:uppercase;line-height:1" class="jsx-1135431938 jsx-2959859206">Aug 05 2017</div><div style="width:293.55375px;padding:0px 12.892499999999998px;position:relative;font-size:12.892499999999998px;letter-spacing:0.03em;text-transform:uppercase;line-height:1" class="jsx-1135431938 jsx-2959859206">post</div></div><div style="margin-bottom:0" class="jsx-1135431938 jsx-2959859206"><div style="font-size:42.974999999999994px;line-height:1.25;padding:0px 12.892499999999998px;width:587.1075px;margin-left:0" class="jsx-1135431938 jsx-2959859206">Why your relationship is likely to last (or not): using Local Interpretable Model-Agnostic Explanations (LIME)</div></div><div style="display:flex;flex-wrap:wrap;width:587.1075px;margin-left:0" class="jsx-1135431938 jsx-2959859206"><div style="padding:12.892499999999998px 12.892499999999998px 0px 12.892499999999998px;width:587.1075px" class="jsx-1135431938 jsx-2959859206"><div class="jsx-1135431938 jsx-2959859206">by<!-- --> <a href="http://www.linkedin.com/in/friederikeschueuer" class="jsx-1135431938 jsx-2959859206">Friederike</a></div></div><div style="width:587.1075px;padding:25.784999999999997px 12.892499999999998px 25.784999999999997px 12.892499999999998px" class="jsx-1135431938 jsx-2959859206"><p><div style="position:relative"><img src="/static/images/2017/09/henry_viii-1504299070584.jpg" style="display:block;margin:0;width:100%"/></div></p><h5>Henry VIII of England had many relationships. We build a classifier to predict whether relationships are going to last, or not, and used Local Interpretable Model-Agnostic Explanations (LIME) to understand the predicted success or failure of given relationships.</h5><p>Last month we launched the latest report and prototype from our machine intelligence R&amp;D team, <a href="http://blog.fastforwardlabs.com/2017/08/02/interpretability.html"><em>Interpretability</em></a>, and we shared our view on <a href="http://blog.fastforwardlabs.com/2017/08/02/business-interpretability.html">why interpretability matters for business</a>.</p><p>On September 6, we will host a <a href="https://mlinterpretability.splashthat.com/">public webinar on interpretability</a> where we&#x27;ll be joined by guests Patrick Hall (Senior Director for Data Science Products at H2o.ai, co-author of <a href="https://www.oreilly.com/ideas/ideas-on-interpreting-machine-learning">Ideas on Interpreting Machine Learning</a>) and Sameer Singh (Assistant Professor of Computer Science at UC Irvine, co-creator of <a href="https://arxiv.org/abs/1602.04938">LIME</a>). There will be lots of opportunities for the audience to ask questions, so we hope you&#x27;ll <a href="https://mlinterpretability.splashthat.com/">join us</a>!</p><p>During our research, we built an interpretability prototype called <em>Refractor</em> to better understand the reasons why a subscription business loses customers. This prototype depends on <em>Local Interpretable Model-Agnostic Explanations</em> (LIME), a new algorithm and open source tool for interpreting the behavior of machine learning models that was released last year (<a href="https://arxiv.org/abs/1602.04938">paper</a>, <a href="https://github.com/marcotcr/lime">code</a>).</p><p>We discuss LIME in depth in our report, but in this article, we take look at it from a conceptual perspective and apply LIME to a binary classification problem: predicting whether couples stay together, or not.</p><h2>Why we need interpretability, especially now</h2><p>Algorithms decide which emails reach our inboxes, whether we are approved for credit, and whom we get the opportunity to date. But, as algorithms give answers, they raise questions. If an algorithm denies your loan application, wouldn&#x27;t you like to know why or what you could change for a more positive outcome? Or perhaps you&#x27;d like to know if your bank is right to trust the algorithm in the first place.</p><p>Fundamentally, machine learning algorithms learn relationships between inputs and outputs. During model training, we supply examples of these inputs and outputs as &quot;learning material&quot; and the algorithm learns the relationship, a parametrized function or trained model. It uses this model to provide outputs for novel inputs.</p><p>Some relationships are simple and can be captured by simple, linear models, which are easy to inspect and understand. For example, the probability of loan default increases with loan amount and decreases with income. These models are interpretable, meaning, they allow a qualitative understanding between inputs and outputs.</p><p><div style="position:relative"><img src="/static/images/2017/08/2_11-1504010664139.png" alt="loan default" style="display:block;margin:0;width:100%"/></div></p><h5>The simple, linear relationship between income, loan amount, and loan default.</h5><p>But some relationships are complex. A customer&#x27;s decisions to cancel a subscription, the focus of our <em>Refractor</em> prototype, or the long-term success of a romantic relationship may depend on multiple factors in non-linear ways. To accurately model these relationships we need models with the flexibility to capture that complexity. Models such as random forests, gradient boosted trees, and neural networks can do just that. But, these complex models are intrinsically difficult to inspect, understand and interpret.</p><p><div style="position:relative"><img src="/static/images/2017/08/2_15-1504010918343.png" alt="complex decision surface" style="display:block;margin:0;width:100%"/></div></p><h5>Complex, non-linear relationships, as shown in this figure, cannot be captured by simple models. Models that can capture this complexity tend to be less interpretable.</h5><h2>The promise of interpretability for practitioners</h2><p>Interpretability means we can understand the reasons why an algorithm gave a particular response. In a recent <a href="http://blog.fastforwardlabs.com/2017/08/02/business-interpretability.html">blog post</a> we cover why, from a business perspective, one should care about interpretability. </p><p>But data scientists and machine learning <em>practitioners</em> benefit from interpretability, too. Interpretability ensures that a model is <em>right</em> for the right reasons and <em>wrong</em> for the right reasons, which traditional measures of model performance, such as model accuracy on the hold-out test set, cannot capture. Insights into the model can help improve it and can help build trust that the model, once deployed, will continue to do a good job.</p><p>One approach to ensure interpretability is to use simple models, but the trade-off between interpretability and accuracy means that, if relationships between inputs and outputs are complex, accuracy will suffer. </p><p><div style="position:relative"><img src="/static/images/2017/08/2_16-1504056142850.png" alt="accuracy vs. interpretability" style="display:block;margin:0;width:100%"/></div></p><h5>More accurate models tend to be harder to inspect and understand.</h5><p>Another option is to use &quot;white-box&quot; models. These have been developed specifically to provide insight into their internal workings without sacrificing model accuracy <em>too much</em>. We cover white-box models in our <a href="http://blog.fastforwardlabs.com/2017/08/02/interpretability.html">report</a>.</p><h2>Model-agnostic interpretability and LIME</h2><p>But what if you don&#x27;t want to (or can&#x27;t) change your model? Perhaps there&#x27;s no other way to get the accuracy you need. Perhaps it&#x27;s already in production. Or perhaps you didn&#x27;t make it and have no idea how it works. In these situation, &quot;model-agnostic&quot; interpretability tools such as LIME may be the right approach (<a href="https://arxiv.org/abs/1602.04938">paper</a>, <a href="https://github.com/marcotcr/lime">code</a>). LIME is based on two simple ideas: perturbation and locally linear approximation.</p><h4>Perturbation</h4><p>Perturbation is probably exactly what you would do if you were asked to explore a black-box model. By repeatedly perturbing the input and observing its effect on the output you can develop an understanding of how different inputs relate to the original output.</p><p>LIME formalizes this idea. It takes a prediction you want to explain and systematically perturbs its inputs. These perturbed inputs become new, labelled training data for a simpler approximate model.</p><h4>Locally linear approximation</h4><p>LIME fits a linear model to describe the relationships between the (perturbed) inputs and outputs. In doing so, it weights generated labels close to the example more heavily to nudge the algorithm to focus on the most relevant part of the &quot;decision function&quot;. So, the simple linear algorithm approximates the more complex, non-linear function learned by the high-accuracy model <em>locally</em>, in the vicinity of the to-be-explained prediction. </p><p><div style="position:relative"><img src="/static/images/2017/08/3_07-1504056507453.png" alt="locally linear approximation" style="display:block;margin:0;width:100%"/></div></p><h5>Even complex decision functions can be approximated <em>locally</em> by simple linear models.</h5><p>Based on two simple ideas, LIME is an exciting breakthrough. It allows you to train a model in <em>any way you like</em> and still have an answer to the local question, &quot;Why has this particular decision been made?&quot;</p><h2>Putting LIME to work, explaining the (predicted) fate of romantic relationships</h2><p>Love endures forever but when it doesn&#x27;t, wouldn&#x27;t you like to know why? We took the Stanford <a href="https://data.stanford.edu/hcmst">HCMST data</a> (How Couples Meet and Stay Together), a longitudinal study on how American&#x27;s meet their partners, and build a classifier to predict whether (and why) couples are likely to stay together. </p><p>We modeled the relationship between couples and their relationship fate using a random forest classifier, a widely used ensemble model that is difficult to inspect and understand. Popular machine learning libraries offer simple ways to implement machine learning routines. We used <code>sklearn</code>&#x27;s&#x27; <code>RandomForestClassifier</code> for model training, <code>GridSearchCV</code> for hyperparameter tuning, and <code>Pipeline</code> to streamline data preprocessing. If you want to see the code, and experiment with LIME, you can access the notebook <a href="https://github.com/fastforwardlabs/couples-lime/blob/master/couples-lime.ipynb">here</a>.</p><p>To explain predictions, once we had a trained model, we needed to instantiate the <code>LimeTabularExplainer</code> object. It takes as inputs a list of feature names (<code>feature_names</code>) and class names (<code>class_names</code>), a list of all categorical variables (<code>categorical_features</code>) and a dictionary of the values of all categorical variables (<code>categorical_names</code>) in addition to the training data; LIME perturbs inputs according to the training data distribution.</p><div><div style="position:relative;margin-bottom:25.784999999999997px;width:602px;margin-left:-20.338749999999997px;margin-right:-20.338749999999997px"><div class="prism-code language-python" style="overflow-x:auto;overflow-y:hidden;background:#f3f3f3"><pre style="float:left;font-size:12.892499999999998px;min-width:100%;position:relative;line-height:1.5;margin:0;padding:12.892499999999998px;overflow:visible"><div class="token-line"><span><span class="token keyword">from</span><span class="token plain"> lime</span><span class="token punctuation">.</span><span class="token plain">lime_tabular </span><span class="token keyword">import</span><span class="token plain"> LimeTabularExplainer</span></span></div><div class="token-line"><span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain"></span><span class="token comment"># The Lime LimeTabularExplainer object</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">explainer </span><span class="token operator">=</span><span class="token plain"> LimeTabularExplainer</span><span class="token punctuation">(</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    train</span><span class="token punctuation">,</span><span class="token plain"> </span><span class="token comment"># training data</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    class_names</span><span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">&#x27;BrokeUp&#x27;</span><span class="token punctuation">,</span><span class="token plain"> </span><span class="token string">&#x27;StayedTogether&#x27;</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token plain"> </span><span class="token comment"># class names</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    feature_names</span><span class="token operator">=</span><span class="token builtin">list</span><span class="token punctuation">(</span><span class="token plain">data</span><span class="token punctuation">.</span><span class="token plain">columns</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token plain"> </span><span class="token comment"># names of all features (regardless of type)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    categorical_features</span><span class="token operator">=</span><span class="token plain">categorical_features</span><span class="token punctuation">,</span><span class="token plain"> </span><span class="token comment"># names of only categorical features</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    categorical_names</span><span class="token operator">=</span><span class="token plain">categorical_names</span><span class="token punctuation">,</span><span class="token plain"> </span><span class="token comment"># labels of all values of all categorical features </span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    discretize_continuous</span><span class="token operator">=</span><span class="token boolean">True</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    </span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain"></span></span></div></pre><div style="position:absolute;left:-1px;top:-1px;height:calc(158.7301587301587% + 2px);width:calc(158.7301587301587% + 2px);transform:scale(0.6300000000000001);transform-origin:left top;border:solid 2px black;pointer-events:none"></div></div></div></div><p>The <code>LimeTabularExplainer</code> object has a method <code>explain_instance</code> that takes an example input and returns the top reasons for its corresponding prediction. The  <code>explain_instance</code> method requires a function (<code>pipeline.predict_proba</code>) as input that takes the &quot;raw&quot; example input data, transforms, scales, one-hot encodes, etc. (as appropriate), and returns its prediction using the trained model. To see how we made ours, see our <a href="https://github.com/fastforwardlabs/couples-lime/blob/master/couples-lime.ipynb">notebook</a>.</p><div><div style="position:relative;margin-bottom:25.784999999999997px;width:602px;margin-left:-20.338749999999997px;margin-right:-20.338749999999997px"><div class="prism-code language-python" style="overflow-x:auto;overflow-y:hidden;background:#f3f3f3"><pre style="float:left;font-size:12.892499999999998px;min-width:100%;position:relative;line-height:1.5;margin:0;padding:12.892499999999998px;overflow:visible"><div class="token-line"><span><span class="token plain">example </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">3</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">exp </span><span class="token operator">=</span><span class="token plain"> explainer</span><span class="token punctuation">.</span><span class="token plain">explain_instance</span><span class="token punctuation">(</span><span class="token plain">test</span><span class="token punctuation">[</span><span class="token plain">example</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token plain"> pipeline</span><span class="token punctuation">.</span><span class="token plain">predict_proba</span><span class="token punctuation">,</span><span class="token plain"> num_features</span><span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain"></span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#x27;Couples probability of staying together:&#x27;</span><span class="token punctuation">,</span><span class="token plain"> exp</span><span class="token punctuation">.</span><span class="token plain">predict_proba</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">exp</span><span class="token punctuation">.</span><span class="token plain">as_pyplot_figure</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain"></span></span></div></pre><div style="position:absolute;left:-1px;top:-1px;height:calc(158.7301587301587% + 2px);width:calc(158.7301587301587% + 2px);transform:scale(0.6300000000000001);transform-origin:left top;border:solid 2px black;pointer-events:none"></div></div></div></div><p><code>sklearn</code>&#x27;s <code>Pipeline</code> streamlines data preprocessing and helps build the function for the <code>lime</code> <code>explain_instance</code> method (see code). Why the trouble, you may wonder? We could supply scaled, one-hot encoded example input to the <code>explain_instance</code> method? </p><p>To explain predictions, we need to be able to <em>understand</em> the reasons returned by solutions like LIME. If LIME returned a sequence of numbers that, mathematically speaking, is a good explanation for a prediction, we would be none the wiser. Explanations needs to be given in a language and at the scale the we can understand; that&#x27;s why we need to bother with <code>Pipeline</code>.</p><h3>Why relationships (are predicted to) fail</h3><p>According to the model, across couples based on random forest&#x27;s feature importances only, your age, your partner&#x27;s age, and the difference in age between partners determines whether couples are going to stay together, or not. LIME shows that the reasons for likely relationship success vary from one couple to the next.</p><p><div style="position:relative"><img src="/static/images/2017/09/lime_3-1504282789410.png" style="display:block;margin:0;width:100%"/></div></p><h5>This couple is likely to stay together, the model gives it a 0.89 probability. LIME informs us that the prediction is due to the fact that the couple is married while their (young) age lowers their chances of relationship &quot;success&quot;.</h5><p><div style="position:relative"><img src="/static/images/2017/09/lime_13-1504299937445.png" style="display:block;margin:0;width:100%"/></div></p><h5>This couple is likely to stay together, the model gives it a 0.75 probability. LIME informs us the prediction is due to the fact that the couple owns their home, they are matched in terms of the level of education, and the respondent is between 43 and 55 years. Curiously, living in an urban area and voting democrat is associated with a lower chance to staying together.</h5><p>LIME captures nuances above feature importances, the variables the trained model deems important globally, across the entire data encountered during training (age, partner&#x27;s age, age difference). LIME focuses on individuals, not global patterns.</p><h2>What LIME reasons are not (good for)</h2><p>How about using algorithms to manage your love life strategically? The model suggests to look for a partner close in age. Should you ask for a pay increase, buy a house, or get married? We asked LIME.</p><p><div style="position:relative"><img src="/static/images/2017/09/pre_marriage_lime-1504283413457.png" style="display:block;margin:0;width:100%"/></div></p><h5>Your chances of staying together aren&#x27;t bad, the model gives is a 0.79. But merely &quot;living together&quot; is hurting your chances, according to LIME.</h5><p>Evaluating different options, getting married leads to the biggest increase in your chance of staying together. But, we advice <em>against</em> marrying tonight&#x27;s Tinder date. It may be tempting to treat LIME&#x27;s reasons as <em>causes</em> of the real-world phenomena the model is predicting; surely, a high amount of debt on my loan application is the reason (read &quot;cause&quot;) for my denied loan application (especially if a smaller debt amount would have changed the outcome).</p><p><div style="position:relative"><img src="/static/images/2017/09/post_marriage_lime-1504283506173.png" style="display:block;margin:0;width:100%"/></div></p><h5>Getting married increases your chance of staying together to 0.91. But, reasons are not causes. We advice against marrying tonight&#x27;s Tinder date.</h5><p>Algorithmic relationship advice should be taken with a grain of salt, LIME reasons are not causes. Interpretability helps us understand the inner workings of models to improve these models, to help build trust in models, and to form hypotheses about phenomena in the real-world captured by models (that warrant rigorous tests). </p><p>What&#x27;s more, LIME picks up on patterns in the data learned by the model, it does not inform about reality. Data reflects current and past conventions and social practices (which we see in our results). LIME is no oracle, but it allows humans to enter a more collaborative relationship with black-box machine learning models, and question them when necessary.</p><h2>How to Access our Reports and Prototypes</h2><p>The future is algorithmic. White-box models and techniques for making black-box models interpretable offer a safer, more productive, and ultimately more collaborative relationship between humans and intelligent machines. We are just at the beginning of the conversation about interpretability and will see the impact over the coming years.</p><p>We offer our research on interpretability in a few ways:</p><ul><li>Annual research subscription (for individuals and corporate members)</li><li>Subscription and advising (research and time with our team)</li><li>Special projects and workshops (help to build a great data product or strategy)</li></ul><p>Email us at <a href="mailto:contact@fastforwardlabs.com">contact@fastforwardlabs.com</a> if you’d like to learn more!</p><div style="display:none;justify-content:center;padding:12.892499999999998px" class="jsx-1135431938 jsx-2959859206"><img style="height:18.75272727272727px;width:18.75272727272727px;position:relative;display:block" src="/static/images/ff.png" class="jsx-1135431938 jsx-2959859206"/></div></div></div></div><div style="position:relative;display:block;width:612.8924999999999px;grid-template-columns:repeat(2, 1fr);margin-left:-12.892499999999998px;margin-right:-12.892499999999998px"><div style="display:grid"><div style="position:relative;display:grid;grid-template-rows:auto 1fr;margin-bottom:12.892499999999998px"><div style="text-transform:uppercase;font-size:12.892499999999998px;letter-spacing:0.03em;line-height:1.5;padding-bottom:6.446249999999999px;padding-left:25.784999999999997px">Newer</div><div style="position:relative;display:grid"><a class="hover-box no-underline no-hover gray-backer hover-extend" style="display:block;position:relative;width:612.8925px;padding-left:12.892499999999998px;padding-right:12.892499999999998px;margin-left:0;margin-right:0" href="/2017/09/01/crowdwork-for-ml.html"><div style="display:flex;flex-wrap:wrap"><div style="display:flex;width:587.1075px;font-size:12.892499999999998px;letter-spacing:0.03em;text-transform:uppercase;line-height:1.5;margin-left:0"><div style="width:293.55375px;padding:12.892499999999998px 12.892499999999998px 0px 12.892499999999998px"><div>Sep 03 2017</div></div><div style="width:293.55375px;padding:12.892499999999998px 12.892499999999998px 0px 12.892499999999998px"><div>post</div></div></div><div style="position:relative;width:587.1075px;padding:12.892499999999998px 0px"><div style="font-size:34.379999999999995px;line-height:1.25;padding:0px 12.892499999999998px;margin-top:-6.446249999999999px"><div style="padding-left:0">Crowdwork for Machine Learning: An Autoethnography</div></div><div style="padding-top:6.446249999999999px;position:relative"><div style="font-size:15.041249999999998px;line-height:1.5em;display:flex;flex-wrap:wrap;padding-left:0"><div style="padding:0px 12.892499999999998px;width:293.55375px"><div style="height:90.24749999999999px;overflow:hidden;display:-webkit-box;-webkit-line-clamp:4;hyphens:auto;-webkit-box-orient:vertical"><span>by <!-- -->Manny<!-- --> ◦ </span>
Amazon’s Mechanical Turk is a platform for soliciting work on online tasks that has been used by market researchers, translators, and data scientists to complete surveys, perform work that cannot be easily automated, and create human-labeled data for supervised learning systems...</div><div style="overflow:hidden;width:100%;text-overflow:ellipsis;white-space:nowrap"><span class="display-link"><span>View<!-- --> <span style="text-transform:lowercase">post</span></span></span></div></div><div style="position:relative;width:293.55375px"><div style="width:calc(100% - 25.784999999999997px);height:calc(100% - 12.892499999999998px);margin-left:12.892499999999998px;margin-top:6.446249999999999px;background-image:url(/static/images/2017/09/the_turk.jpg);background-size:contain;background-position:center center;background-repeat:no-repeat"></div></div></div></div></div></div></a><div style="position:absolute;left:-1px;top:-1px;height:calc(158.7301587301587% + 2px);width:calc(158.7301587301587% + 2px);transform:scale(0.6300000000000001);transform-origin:left top;border:solid 2px black;pointer-events:none"></div></div></div></div><div style="display:grid"><div style="position:relative;display:grid;grid-template-rows:auto 1fr;margin-bottom:12.892499999999998px"><div style="text-transform:uppercase;font-size:12.892499999999998px;letter-spacing:0.03em;line-height:1.5;padding-bottom:6.446249999999999px;padding-left:25.784999999999997px">Older</div><div style="position:relative;display:grid"><a class="hover-box no-underline no-hover gray-backer hover-extend" style="display:block;position:relative;width:612.8925px;padding-left:12.892499999999998px;padding-right:12.892499999999998px;margin-left:0;margin-right:0" href="/2017/08/08/encartopedia.html"><div style="display:flex;flex-wrap:wrap"><div style="display:flex;width:587.1075px;font-size:12.892499999999998px;letter-spacing:0.03em;text-transform:uppercase;line-height:1.5;margin-left:0"><div style="width:293.55375px;padding:12.892499999999998px 12.892499999999998px 0px 12.892499999999998px"><div>Aug 03 2017</div></div><div style="width:293.55375px;padding:12.892499999999998px 12.892499999999998px 0px 12.892499999999998px"><div>post</div></div></div><div style="position:relative;width:587.1075px;padding:12.892499999999998px 0px"><div style="font-size:34.379999999999995px;line-height:1.25;padding:0px 12.892499999999998px;margin-top:-6.446249999999999px"><div style="padding-left:0">Encartopedia</div></div><div style="padding-top:6.446249999999999px;position:relative"><div style="font-size:15.041249999999998px;line-height:1.5em;display:flex;flex-wrap:wrap;padding-left:0"><div style="padding:0px 12.892499999999998px;width:293.55375px"><div style="height:90.24749999999999px;overflow:hidden;display:-webkit-box;-webkit-line-clamp:4;hyphens:auto;-webkit-box-orient:vertical"><span>by <!-- -->Sepand<!-- --> ◦ </span>
Tabula Rogeriana

The Tabula Rogeriana, a world map created by Muhammad al-Idrisi through traveler interviews in 1154.

The Wikipedia corpus is one of the favorite datasets of the machine learning community. It is often used for experimenting, benchmarking and providing how-to...</div><div style="overflow:hidden;width:100%;text-overflow:ellipsis;white-space:nowrap"><span class="display-link"><span>View<!-- --> <span style="text-transform:lowercase">post</span></span></span></div></div><div style="position:relative;width:293.55375px"><div style="width:calc(100% - 25.784999999999997px);height:calc(100% - 12.892499999999998px);margin-left:12.892499999999998px;margin-top:6.446249999999999px;background-image:url(/static/images/2017/08/enc-tabula.jpg);background-size:contain;background-position:center center;background-repeat:no-repeat"></div></div></div></div></div></div></a><div style="position:absolute;left:-1px;top:-1px;height:calc(158.7301587301587% + 2px);width:calc(158.7301587301587% + 2px);transform:scale(0.6300000000000001);transform-origin:left top;border:solid 2px black;pointer-events:none"></div></div></div></div></div><div style="padding-bottom:25.784999999999997px;padding-top:25.784999999999997px" class="jsx-1135431938 jsx-2959859206"><div style="font-size:34.379999999999995px;line-height:1.25;padding:0px 12.892499999999998px 0px 12.892499999999998px;margin-bottom:12.892499999999998px;width:587.1075px;margin-left:0" class="jsx-1135431938 jsx-2959859206">About</div><div style="padding:0px 12.892499999999998px;margin-bottom:12.892499999999998px;width:587.1075px;margin-left:0;font-size:17.189999999999998px;line-height:1.5" class="jsx-1135431938 jsx-2959859206">Cloudera Fast Forward Labs is an applied machine learning research group. We help organizations recognize and develop new product and business opportunities through emerging technologies.<!-- --> </div><div style="padding:0px 12.892499999999998px;margin-bottom:12.892499999999998px;width:587.1075px;margin-left:0;font-size:17.189999999999998px;line-height:1.5" class="jsx-1135431938 jsx-2959859206"><a href="https://www.cloudera.com/products/fast-forward-labs-research.html" class="jsx-1135431938 jsx-2959859206">Learn more about working with us.</a></div></div></div><div class="jsx-1135431938 jsx-2959859206"><div style="position:relative" class="jsx-1135431938 jsx-2959859206"><div style="position:absolute;left:0;width:100%;height:2px;transform:scaleY(0.60165);transform-origin:center center;background:black;top:-1px"></div><div style="padding:12.892499999999998px;display:flex;justify-content:space-between;flex-wrap:wrap;font-size:17.189999999999998px;line-height:1.5" class="jsx-1135431938 jsx-2959859206"><div class="jsx-1135431938 jsx-2959859206"><a href="/" class="jsx-1135431938 jsx-2959859206">Blog</a></div><div style="display:flex;flex-wrap:wrap" class="jsx-1135431938 jsx-2959859206"><div style="margin-right:12.892499999999998px" class="jsx-1135431938 jsx-2959859206"><a href="https://www.cloudera.com/products/fast-forward-labs-research.html" class="jsx-1135431938 jsx-2959859206">Cloudera</a></div><div style="margin-right:12.892499999999998px" class="jsx-1135431938 jsx-2959859206"><a href="https://blog.fastforwardlabs.com/" class="jsx-1135431938 jsx-2959859206">AI Experiments</a></div><div class="jsx-1135431938 jsx-2959859206"><a href="https://twitter.com/fastforwardlabs" class="jsx-1135431938 jsx-2959859206">Twitter</a></div></div></div></div></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{}},"page":"/posts/2017-09-01-LIME-for-couples","query":{},"buildId":"EnU~FBvqy_55fWO5RkIyH","nextExport":true}</script><script async="" id="__NEXT_PAGE__/posts/2017-09-01-LIME-for-couples" src="/_next/static/EnU~FBvqy_55fWO5RkIyH/pages/posts/2017-09-01-LIME-for-couples.js"></script><script async="" id="__NEXT_PAGE__/_app" src="/_next/static/EnU~FBvqy_55fWO5RkIyH/pages/_app.js"></script><script src="/_next/static/runtime/webpack-fdce77a122c11e06ae50.js" async=""></script><script src="/_next/static/chunks/commons.f77b50de979bfbbb280b.js" async=""></script><script src="/_next/static/runtime/main-5ab107747766f1b4e0bf.js" async=""></script></body></html>