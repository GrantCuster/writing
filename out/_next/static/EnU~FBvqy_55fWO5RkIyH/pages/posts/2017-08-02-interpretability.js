(window.webpackJsonp=window.webpackJsonp||[]).push([["3958"],{gPgr:function(e,t,n){(window.__NEXT_P=window.__NEXT_P||[]).push(["/posts/2017-08-02-interpretability",function(){var e=n("hbxf");return{page:e.default||e}}])},hbxf:function(e,t,n){"use strict";n.r(t),n.d(t,"frontMatter",function(){return o}),n.d(t,"default",function(){return c});var a=n("kOwS"),r=n("qNsG"),i=(n("q1tI"),n("E/Ix")),o={layout:"post",title:"New Research on Interpretability",date:"2017-08-02 09:00",preview_image:"/images/2017/08/ff06-animation.gif",author:"Mike",author_link:"https://twitter.com/mikepqr",feature:!0,published:!0},s={frontMatter:o},l="wrapper";function c(e){var t=e.components,n=Object(r.a)(e,["components"]);return Object(i.b)(l,Object(a.a)({},s,n,{components:t,mdxType:"MDXLayout"}),Object(i.b)("p",null,"We're excited to release the latest prototype and report from our machine\nintelligence R&D team: ",Object(i.b)("em",{parentName:"p"},"Interpretability"),"."),Object(i.b)("p",null,Object(i.b)("img",Object(a.a)({parentName:"p"},{src:"/images/2017/08/ff06-animation.gif",alt:"FF06 Interpretability"}))),Object(i.b)("p",null,"An interpretable algorithm is one whose decisions you can explain. You can\nbetter rely on such a model to be safe, accurate and useful."),Object(i.b)("p",null,"Our prototype shows how new ideas in interpretability research can be used to\nextract actionable insight from black-box machine learning models."),Object(i.b)("p",null,"And our report describes breakthroughs in interpretability research and places\nthem in a commercial, legal and ethical context."),Object(i.b)("p",null,"This research is relevant to anyone who designs systems using machine learning,\nfrom engineers and data scientists, to business leaders and executives who are\nconsidering new product opportunities."),Object(i.b)("h2",null,"The Power of Interpretability"),Object(i.b)("p",null,"A model you can interpret and understand is one you can more easily improve. It\nis also one you, regulators, and society can more easily trust to be safe and\nnondiscriminatory. And an accurate model that is also interpretable can offer\ninsights that can be used to change real-world outcomes for the better."),Object(i.b)("p",null,Object(i.b)("img",Object(a.a)({parentName:"p"},{src:"/images/2017/08/howdoesanyofthiswork.png",alt:"How does any of this work"}))),Object(i.b)("p",null,"There is a central tension, however, between accuracy and interpretability: the\nmost accurate models are necessarily the hardest to understand. Our report\nlooks closely at two recent breakthroughs that resolve this tension. New\nwhite-box algorithms offer better performance while guaranteeing\ninterpretability. Meanwhile, model-agnostic interpretability techniques allow\nyou to peer inside black-box models."),Object(i.b)("p",null,"Our report explains how these techniques work at both a conceptual and\ntechnical level, and then discusses the commercial opportunities for their\napplication."),Object(i.b)("p",null,Object(i.b)("img",Object(a.a)({parentName:"p"},{src:"/images/2017/08/refractor.gif",alt:"Refractor"}))),Object(i.b)("p",null,"Our prototype, meanwhile, makes these possibilities concrete. We applied a\nmodel-agnostic tool called LIME to a black-box model, in order to better\nunderstand the reasons a subscription business loses customers. An accurate\nmodel that predicts which customers your business is about to lose is useful.\nBut it’s much more useful if you can also see ",Object(i.b)("em",{parentName:"p"},"why")," they are about to leave. In\nthis way, you learn about weaknesses in your business, and can perhaps even\nintervene to prevent the losses."),Object(i.b)("h2",null,"More Important than Ever"),Object(i.b)("p",null,"Work on machine learning interpretability is more important than ever. Our\nsociety is increasingly dependent on intelligent machines. Algorithms govern\neverything from which e-mails reach our inboxes to whether we are approved for\ncredit to whom we get the opportunity to date. And their impact on our\nexperience of the world is growing."),Object(i.b)("p",null,"This rise in the use of algorithms coincides with a surge in the capabilities\nof black-box techniques, or algorithms whose inner workings cannot easily be\nexplained. The question of interpretability has been important in applied\nmachine learning for many years, but as relatively uninterpretable techniques\nlike deep learning grow in popularity, it’s becoming an urgent concern. These\ntechniques offer breakthrough capabilities in analyzing and even generating\nrich media and text data, but it's often hard to figure out ",Object(i.b)("em",{parentName:"p"},"how")," they do what\nthey do."),Object(i.b)("p",null,"The future is algorithmic. Interpretable models offer a safer, more productive,\nand ultimately more collaborative relationship between humans and intelligent\nmachines."),Object(i.b)("h2",null,"Learn More"),Object(i.b)("p",null,"We will host a ",Object(i.b)("a",Object(a.a)({parentName:"p"},{href:"https://mlinterpretability.splashthat.com/"}),"public webinar on\ninterpretability")," on September 6 2017. We'll be joined by guests Patrick Hall (Senior Data Scientist at H2O,\nco-author of ",Object(i.b)("a",Object(a.a)({parentName:"p"},{href:"https://www.oreilly.com/ideas/ideas-on-interpreting-machine-learning"}),"Ideas on Interpreting Machine\nLearning"),")\nand Sameer Singh (Assistant Professor of Computer Science at UC Irvine,\nco-creator of LIME, a model-agnostic tool for extracting explanations from\nblack box machine learning models). "),Object(i.b)("h2",null,"How to Access our Reports and Prototypes"),Object(i.b)("p",null,"We offer our research on interpretability in a few ways:"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Annual research subscription (for individuals and corporate members)"),Object(i.b)("li",{parentName:"ul"},"Subscription and advising (research and time with our team)"),Object(i.b)("li",{parentName:"ul"},"Special projects and workshops (help to build a great data product or strategy)")),Object(i.b)("p",null,"Email us at ",Object(i.b)("a",Object(a.a)({parentName:"p"},{href:"mailto:contact@fastforwardlabs.com"}),"contact@fastforwardlabs.com")," if you’d like to learn more!"))}c.isMDXComponent=!0}},[["gPgr","5d41","9da1"]]]);