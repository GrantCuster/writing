<!DOCTYPE html><html><head><link rel="preload" href="/static/fonts/Inter-Regular.woff2?v=3.5" as="font" type="font/woff2" crossorigin="*"/><link rel="preload" href="/static/fonts/Inter-Italic.woff2?v=3.5" as="font" type="font/woff2" crossorigin="*"/><link href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css" rel="stylesheet"/><meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1" class="next-head"/><meta charSet="utf-8" class="next-head"/><style class="next-head">.js-no-flash { display: none }</style><noscript class="jsx-4059783939 jsx-3344216300 next-head"><style>.js-no-flash { display: block }</style></noscript><link rel="icon" type="image/x-icon" href="static/images/favicon.png" class="jsx-1135431938 jsx-2959859206 next-head"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous" class="jsx-1135431938 jsx-2959859206 next-head"/><title class="jsx-1135431938 jsx-2959859206 next-head">PyTorch for Recommenders 101 - Cloudera Fast Forward</title><link rel="preload" href="/_next/static/EnU~FBvqy_55fWO5RkIyH/pages/posts/2018-04-10-pytorch-for-recommenders-101.js" as="script"/><link rel="preload" href="/_next/static/EnU~FBvqy_55fWO5RkIyH/pages/_app.js" as="script"/><link rel="preload" href="/_next/static/runtime/webpack-fdce77a122c11e06ae50.js" as="script"/><link rel="preload" href="/_next/static/chunks/commons.f77b50de979bfbbb280b.js" as="script"/><link rel="preload" href="/_next/static/runtime/main-5ab107747766f1b4e0bf.js" as="script"/><style id="__jsx-4059783939">@font-face{font-family:'Inter';font-style:normal;font-weight:400;src:url('/static/fonts/Inter-Regular.woff2?v=3.5') format('woff2'), url('/static/fonts/Inter-Regular.woff?v=3.5') format('woff');}@font-face{font-family:'Inter';font-style:italic;font-weight:400;src:url('/static/fonts/Inter-Italic.woff2?v=3.5') format('woff2'), url('/static/fonts/Inter-Italic.woff?v=3.5') format('woff');}@font-face{font-family:'Inter';font-style:normal;font-weight:700;src:url('/static/fonts/Inter-Bold.woff2?v=3.5') format('woff2'), url('/static/fonts/Inter-Bold.woff?v=3.5') format('woff');}@font-face{font-family:'Inter';font-style:italic;font-weight:700;src:url('/static/fonts/Inter-BoldItalic.woff2?v=3.5') format('woff2'), url('/static/fonts/Inter-BoldItalic.woff?v=3.5') format('woff');}*{box-sizing:border-box;}html{font-family:'Inter',serif;font-size:18px;line-height:27px;text-rendering:optimizelegibility;font-feature-settings:'kern';font-kerning:normal;font-feature-settings:'ss02' 1;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;}pre{-webkit-font-smoothing:auto;-moz-osx-font-smoothing:auto;overflow-x:auto;font-family:SFMono-Regular,Consolas,Liberation Mono,Menlo, Monaco,Courier New,monospace;}body{margin:0;overflow-x:hidden;}a{color:inherit;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:opacity 0.025s linear;transition:opacity 0.025s linear;}a:hover{opacity:0.75;}a.no-hover:hover{opacity:1;}.hover_box_overlay{opacity:0;-webkit-transition:opacity 0.025s linear;transition:opacity 0.025s linear;}.hover_box:hover .hover_box_overlay{opacity:1;}a.gray-backer{-webkit-transition:background 0.05s linear;transition:background 0.05s linear;}a.gray-backer:hover{background:#f3f3f3;}button:focus{outline:#999 auto 3px;}</style><style id="__jsx-3344216300">html{font-size:17.189999999999998px;line-height:25.784999999999997px;}a,.display-link{background-image:linear-gradient( to right, black 100%, transparent 0% );background-position:0em calc(1.07em);background-repeat:repeat-x;background-size:1em 0.07em;}a.no-underline{background-image:none;}a.no-hover{background-image:none;}a.no-hover:hover{background-image:none;opacity:1;}</style><style id="__jsx-2959859206">h1,h2,h3,h4,h5,h6{font-weight:400;font-style:normal;margin:0;}h1{font-size:51.56999999999999px;line-height:1.25;}h2{font-size:34.379999999999995px;line-height:1.25;padding-top:25.784999999999997px;margin-bottom:25.784999999999997px;}h3{font-size:25.784999999999997px;line-height:1.25;padding-top:25.784999999999997px;margin-bottom:25.784999999999997px;}h4{font-size:21.487499999999997px;line-height:1.25;padding-top:0px;margin-bottom:25.784999999999997px;}h5{font-size:12.892499999999998px;line-height:1.4375;margin-bottom:12.892499999999998px;padding-bottom:12.892499999999998px;margin-top:-12.892499999999998px;}p{margin:0 0 25.784999999999997px 0;}ol,ul{margin:0 0 25.784999999999997px 0;padding-left:25.784999999999997px;}blockquote{margin:0 0 25.784999999999997px 25.784999999999997px;}.html-video-holder{margin:0 0 25.784999999999997px 0;}video{max-width:100%;}code{background:#eaeaea;padding-right:3px;padding-left:3px;font-size:0.975em;word-break:break-word;}</style><style id="__jsx-1135431938">code[class*='language-'],pre[class*='language-']{color:black;background:none;font-family:Consolas,Monaco,'Andale Mono','Ubuntu Mono', monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;}pre[class*='language-']::-moz-selection,pre[class*='language-']::-moz-selection,code[class*='language-']::-moz-selection,code[class*='language-']::-moz-selection{text-shadow:none;}pre[class*='language-']::selection,pre[class*='language-']::selection,code[class*='language-']::selection,code[class*='language-']::selection{text-shadow:none;}@media print{code[class*='language-'],pre[class*='language-']{text-shadow:none;}}:not(pre)>code[class*='language-']{white-space:normal;}.token.comment,.token.prolog,.token.doctype,.token.cdata{color:slategray;}.token.punctuation{color:#999;}.namespace{opacity:0.7;}.token.property,.token.tag,.token.boolean,.token.number,.token.constant,.token.symbol,.token.deleted{color:#905;}.token.selector,.token.attr-name,.token.string,.token.char,.token.builtin,.token.inserted{color:#690;}.token.operator,.token.entity,.token.url,.language-css .token.string,.style .token.string{color:#9a6e3a;}.token.atrule,.token.attr-value,.token.keyword{color:#07a;}.token.function,.token.class-name{color:#dd4a68;}.token.regex,.token.important,.token.variable{color:#e90;}.token.important,.token.bold{font-weight:bold;}.token.italic{font-style:italic;}.token.entity{cursor:help;}</style></head><body><div id="__next"><div class="jsx-4059783939 jsx-3344216300 js-no-flash"><div style="padding-bottom:12.892499999999998px"><div style="position:relative"><div style="position:relative;padding:6.446249999999999px 12.892499999999998px 6.446249999999999px 12.892499999999998px;background-image:url(&quot;/static/images/dataline.png&quot;)"><div style="display:flex;justify-content:space-between"><div style="display:flex;align-items:center;height:25.784999999999997px;padding-top:1px"><a href="https://www.cloudera.com/products/fast-forward-labs-research.html" style="display:block;line-height:0" class="no-underline no-hover"><img style="height:12.892499999999998px" src="/static/images/cloudera.png"/></a></div><div style="display:flex;align-items:center;padding-top:1px;font-size:17.189999999999998px;line-height:1.5"><a class="no-underline" href="https://www.cloudera.com/products/fast-forward-labs-research.html" style="color:#333e47;font-size:12.892499999999998px;line-height:1.5">About Us â†’</a></div></div><div style="position:absolute;left:0;width:100%;height:2px;transform:scaleY(0.60165);transform-origin:center center;background:rgba(0,0,0,0.125);bottom:-1px"></div></div><div style="padding:12.892499999999998px 12.892499999999998px 12.892499999999998px 12.892499999999998px;display:flex;justify-content:space-between;font-size:17.189999999999998px;line-height:1.5"><div style="display:flex;align-items:center"><a class="no-hover no-underline" style="display:flex;align-items:center" href="/"><img style="height:18.75272727272727px;width:18.75272727272727px;margin-right:9.669374999999999px;position:relative;top:-0.5860227272727272px" src="/static/images/ff.png"/><div>Fast Forward Labs </div></a></div><div style="display:flex;align-items:center;height:25.784999999999997px"></div><div style="display:flex"><div style="margin-right:12.892499999999998px"><a href="/">Blog</a></div><div><a href="https://experiments.fastforwardlabs.com">AI Experiments</a></div></div></div><div style="position:absolute;left:0;width:100%;height:2px;transform:scaleY(0.60165);transform-origin:center center;background:black;bottom:-1px"></div></div></div><div class="jsx-1135431938 jsx-2959859206"><div style="position:relative" class="jsx-1135431938 jsx-2959859206"><div style="padding-left:6.446249999999999px;padding-right:6.446249999999999px;padding-top:25.784999999999997px" class="jsx-1135431938 jsx-2959859206"><div class="jsx-1135431938 jsx-2959859206"><div style="display:flex;margin-bottom:12.892499999999998px;width:587.1075px;margin-left:0" class="jsx-1135431938 jsx-2959859206"><div style="width:293.55375px;padding:0px 12.892499999999998px;position:relative;font-size:12.892499999999998px;letter-spacing:0.03em;text-transform:uppercase;line-height:1" class="jsx-1135431938 jsx-2959859206">Apr 03 2018</div><div style="width:293.55375px;padding:0px 12.892499999999998px;position:relative;font-size:12.892499999999998px;letter-spacing:0.03em;text-transform:uppercase;line-height:1" class="jsx-1135431938 jsx-2959859206">post</div></div><div style="margin-bottom:0" class="jsx-1135431938 jsx-2959859206"><div style="font-size:42.974999999999994px;line-height:1.25;padding:0px 12.892499999999998px;width:587.1075px;margin-left:0" class="jsx-1135431938 jsx-2959859206">PyTorch for Recommenders 101</div></div><div style="display:flex;flex-wrap:wrap;width:587.1075px;margin-left:0" class="jsx-1135431938 jsx-2959859206"><div style="padding:12.892499999999998px 12.892499999999998px 0px 12.892499999999998px;width:587.1075px" class="jsx-1135431938 jsx-2959859206"><div class="jsx-1135431938 jsx-2959859206">by<!-- --> <a href="https://twitter.com/shioulin_sam" class="jsx-1135431938 jsx-2959859206">Shioulin</a></div></div><div style="width:587.1075px;padding:25.784999999999997px 12.892499999999998px 25.784999999999997px 12.892499999999998px" class="jsx-1135431938 jsx-2959859206"><p>Recommenders, generally associated with e-commerce, sift though a huge inventory
of available items to find and recommend ones that a user will like. Different
from search, recommenders rely on historical data to tease out user
preference. How does a recommender accomplish this? In this post we explore
building simple recommendation systems in <a href="http://pytorch.org/">PyTorch</a> using
the <a href="https://grouplens.org/datasets/movielens/100k/">Movielens 100K data</a>, which
has 100,000 ratings (1-5) that 943 users provided on 1682 movies. </p><h2>Matrix Factorization</h2><p><div style="position:relative"><img src="/static/images/editor_uploads/2018-04-11-175944-02_07.png" alt="Diagram of a simple recommendation system. It moves from Step 1: User, to Step 2: Connected Factors, to Step 3: Recommended items based on the connected factors." style="display:block;margin:0;width:100%"/></div></p><p>We first build a traditional recommendation system based on <a href="https://datajobs.com/data-science-repo/Recommender-Systems-%5BNetflix%5D.pdf">matrix
factorization</a>. The
input data is an interaction matrix where each row represents a user and each
column represents an item. The rating assigned by a user for a particular item
is found in the corresponding row and column of the interaction matrix. This
matrix is generally large but sparse; there are many items and users but a
single user would only have interacted with a small subset of items. Matrix
factorization decomposes this larger matrix into two smaller matrices - the
first one maps users into a set of factors and the second maps items into the
same set of factors. Multiplying these two smaller matrices together gives an
approximation to the original matrix, with values for empty elements
inferred. To predict a rating for a user-item pair, we simply multiply the row
representing the user from the first matrix with the column representing the
item from the second matrix.</p><p>In PyTorch we can implement a version of matrix factorization by using the
embedding layer to &quot;map&quot; users into a set of factors. The number of factors
determine the size of the embedding vector. Similarly we map items into their
own embedding layer. Both user and item embeddings have the same size. To
predict a user-item rating, we multiply the user embeddings with item embeddings
and sum to obtain one number. The following code draws from <a href="https://github.com/EthanRosenthal/torchmf/blob/master/torchmf.py">Ethan Rosenthal&#x27;s
work on matrix factorization in
PyTorch</a>.</p><div><div style="position:relative;margin-bottom:25.784999999999997px;width:602px;margin-left:-20.338749999999997px;margin-right:-20.338749999999997px"><div class="prism-code language-python" style="overflow-x:auto;overflow-y:hidden;background:#f3f3f3"><pre style="float:left;font-size:12.892499999999998px;min-width:100%;position:relative;line-height:1.5;margin:0;padding:12.892499999999998px;overflow:visible"><div class="token-line"><span><span class="token keyword">import</span><span class="token plain"> torch</span></span></div><div class="token-line"><span><span class="token plain"></span><span class="token keyword">from</span><span class="token plain"> torch</span><span class="token punctuation">.</span><span class="token plain">autograd </span><span class="token keyword">import</span><span class="token plain"> Variable</span></span></div><div class="token-line"><span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain"></span><span class="token keyword">class</span><span class="token plain"> </span><span class="token class-name">MatrixFactorization</span><span class="token punctuation">(</span><span class="token plain">torch</span><span class="token punctuation">.</span><span class="token plain">nn</span><span class="token punctuation">.</span><span class="token plain">Module</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    </span><span class="token keyword">def</span><span class="token plain"> </span><span class="token function">__init__</span><span class="token punctuation">(</span><span class="token plain">self</span><span class="token punctuation">,</span><span class="token plain"> n_users</span><span class="token punctuation">,</span><span class="token plain"> n_items</span><span class="token punctuation">,</span><span class="token plain"> n_factors</span><span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        </span><span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token plain">__init__</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    </span><span class="token comment"># create user embeddings</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        self</span><span class="token punctuation">.</span><span class="token plain">user_factors </span><span class="token operator">=</span><span class="token plain"> torch</span><span class="token punctuation">.</span><span class="token plain">nn</span><span class="token punctuation">.</span><span class="token plain">Embedding</span><span class="token punctuation">(</span><span class="token plain">n_users</span><span class="token punctuation">,</span><span class="token plain"> n_factors</span><span class="token punctuation">,</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">                                               sparse</span><span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    </span><span class="token comment"># create item embeddings</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        self</span><span class="token punctuation">.</span><span class="token plain">item_factors </span><span class="token operator">=</span><span class="token plain"> torch</span><span class="token punctuation">.</span><span class="token plain">nn</span><span class="token punctuation">.</span><span class="token plain">Embedding</span><span class="token punctuation">(</span><span class="token plain">n_items</span><span class="token punctuation">,</span><span class="token plain"> n_factors</span><span class="token punctuation">,</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">                                               sparse</span><span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    </span><span class="token keyword">def</span><span class="token plain"> </span><span class="token function">forward</span><span class="token punctuation">(</span><span class="token plain">self</span><span class="token punctuation">,</span><span class="token plain"> user</span><span class="token punctuation">,</span><span class="token plain"> item</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        </span><span class="token comment"># matrix multiplication</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        </span><span class="token keyword">return</span><span class="token plain"> </span><span class="token punctuation">(</span><span class="token plain">self</span><span class="token punctuation">.</span><span class="token plain">user_factors</span><span class="token punctuation">(</span><span class="token plain">user</span><span class="token punctuation">)</span><span class="token operator">*</span><span class="token plain">self</span><span class="token punctuation">.</span><span class="token plain">item_factors</span><span class="token punctuation">(</span><span class="token plain">item</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    </span><span class="token keyword">def</span><span class="token plain"> </span><span class="token function">predict</span><span class="token punctuation">(</span><span class="token plain">self</span><span class="token punctuation">,</span><span class="token plain"> user</span><span class="token punctuation">,</span><span class="token plain"> item</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        </span><span class="token keyword">return</span><span class="token plain"> self</span><span class="token punctuation">.</span><span class="token plain">forward</span><span class="token punctuation">(</span><span class="token plain">user</span><span class="token punctuation">,</span><span class="token plain"> item</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain"></span></span></div></pre><div style="position:absolute;left:-1px;top:-1px;height:calc(158.7301587301587% + 2px);width:calc(158.7301587301587% + 2px);transform:scale(0.6300000000000001);transform-origin:left top;border:solid 2px black;pointer-events:none"></div></div></div></div><p>To fit the matrix factorization model we need to pick a loss function and an
optimizer. In this example we use the average squared distance between the
prediction and the actual value as a loss function, this is known as
mean-squared error. We then try to minimize this loss by using stochastic
gradient descent. The code below shows how the model is fitted in four steps: i)
pass in a user-item pair, ii) forward pass to compute the predicted rating, iii)
compute the loss, and iv) backpropagate to compute gradients and update the
weights. </p><div><div style="position:relative;margin-bottom:25.784999999999997px;width:602px;margin-left:-20.338749999999997px;margin-right:-20.338749999999997px"><div class="prism-code language-python" style="overflow-x:auto;overflow-y:hidden;background:#f3f3f3"><pre style="float:left;font-size:12.892499999999998px;min-width:100%;position:relative;line-height:1.5;margin:0;padding:12.892499999999998px;overflow:visible"><div class="token-line"><span><span class="token plain">model </span><span class="token operator">=</span><span class="token plain"> MatrixFactorization</span><span class="token punctuation">(</span><span class="token plain">n_users</span><span class="token punctuation">,</span><span class="token plain"> n_items</span><span class="token punctuation">,</span><span class="token plain"> n_factors</span><span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">loss_fn </span><span class="token operator">=</span><span class="token plain"> torch</span><span class="token punctuation">.</span><span class="token plain">nn</span><span class="token punctuation">.</span><span class="token plain">MSELoss</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token plain"> </span></span></div><div class="token-line"><span><span class="token plain">optimizer </span><span class="token operator">=</span><span class="token plain"> torch</span><span class="token punctuation">.</span><span class="token plain">optim</span><span class="token punctuation">.</span><span class="token plain">SGD</span><span class="token punctuation">(</span><span class="token plain">model</span><span class="token punctuation">.</span><span class="token plain">parameters</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">                            lr</span><span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain"></span><span class="token keyword">for</span><span class="token plain"> user</span><span class="token punctuation">,</span><span class="token plain"> item </span><span class="token keyword">in</span><span class="token plain"> </span><span class="token builtin">zip</span><span class="token punctuation">(</span><span class="token plain">users</span><span class="token punctuation">,</span><span class="token plain"> items</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    </span><span class="token comment"># get user, item and rating data</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    rating </span><span class="token operator">=</span><span class="token plain"> Variable</span><span class="token punctuation">(</span><span class="token plain">torch</span><span class="token punctuation">.</span><span class="token plain">FloatTensor</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token plain">ratings</span><span class="token punctuation">[</span><span class="token plain">user</span><span class="token punctuation">,</span><span class="token plain"> item</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    user </span><span class="token operator">=</span><span class="token plain"> Variable</span><span class="token punctuation">(</span><span class="token plain">torch</span><span class="token punctuation">.</span><span class="token plain">LongTensor</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token plain">user</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    item </span><span class="token operator">=</span><span class="token plain"> Variable</span><span class="token punctuation">(</span><span class="token plain">torch</span><span class="token punctuation">.</span><span class="token plain">LongTensor</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token plain">item</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    </span><span class="token comment"># predict</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    prediction </span><span class="token operator">=</span><span class="token plain"> model</span><span class="token punctuation">(</span><span class="token plain">user</span><span class="token punctuation">,</span><span class="token plain"> item</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    loss </span><span class="token operator">=</span><span class="token plain"> loss_fn</span><span class="token punctuation">(</span><span class="token plain">prediction</span><span class="token punctuation">,</span><span class="token plain"> rating</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    </span><span class="token comment"># backpropagate</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    loss</span><span class="token punctuation">.</span><span class="token plain">backward</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    </span><span class="token comment"># update weights</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    optimizer</span><span class="token punctuation">.</span><span class="token plain">step</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain"></span></span></div></pre><div style="position:absolute;left:-1px;top:-1px;height:calc(158.7301587301587% + 2px);width:calc(158.7301587301587% + 2px);transform:scale(0.6300000000000001);transform-origin:left top;border:solid 2px black;pointer-events:none"></div></div></div></div><p>We train this model on the Movielens dataset with ratings scaled between <!-- -->[0, 1]<!-- -->
to help with convergence. Applied on the test set, we obtain a root mean-squared
error(RMSE) of 0.66. This means that on average, the difference between our
prediction and the actual value is 0.66!</p><h2>Dense Feedforward Neural Network</h2><p>Given the underwhelming performance of our matrix factorization model, we try a
simple feedforward recommendation system instead. The input to this neural
network is a pair of user and item represented by their IDs. Both user and item
IDs first pass through an embedding layer. The output of the embedding layer,
which are two embedding vectors, are then concatenated into one and passed into
a linear network. The output of the linear network is one dimensional -
representing the rating for the user-item pair. The model is fit the same way as
the matrix factorization model and uses the standard PyTorch approach of forward
passing, computing the loss, backpropagating and updating weights.</p><div><div style="position:relative;margin-bottom:25.784999999999997px;width:602px;margin-left:-20.338749999999997px;margin-right:-20.338749999999997px"><div class="prism-code language-python" style="overflow-x:auto;overflow-y:hidden;background:#f3f3f3"><pre style="float:left;font-size:12.892499999999998px;min-width:100%;position:relative;line-height:1.5;margin:0;padding:12.892499999999998px;overflow:visible"><div class="token-line"><span><span class="token keyword">import</span><span class="token plain"> torch</span></span></div><div class="token-line"><span><span class="token plain"></span><span class="token keyword">import</span><span class="token plain"> torch</span><span class="token punctuation">.</span><span class="token plain">nn</span><span class="token punctuation">.</span><span class="token plain">functional </span><span class="token keyword">as</span><span class="token plain"> F</span></span></div><div class="token-line"><span><span class="token plain"></span><span class="token keyword">from</span><span class="token plain"> torch</span><span class="token punctuation">.</span><span class="token plain">autograd </span><span class="token keyword">import</span><span class="token plain"> Variable</span></span></div><div class="token-line"><span><span class="token plain"></span><span class="token keyword">from</span><span class="token plain"> torch </span><span class="token keyword">import</span><span class="token plain"> nn</span></span></div><div class="token-line"><span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain"></span><span class="token keyword">class</span><span class="token plain"> </span><span class="token class-name">DenseNet</span><span class="token punctuation">(</span><span class="token plain">nn</span><span class="token punctuation">.</span><span class="token plain">Module</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    </span><span class="token keyword">def</span><span class="token plain"> </span><span class="token function">__init__</span><span class="token punctuation">(</span><span class="token plain">self</span><span class="token punctuation">,</span><span class="token plain"> n_users</span><span class="token punctuation">,</span><span class="token plain"> n_items</span><span class="token punctuation">,</span><span class="token plain"> n_factors</span><span class="token punctuation">,</span><span class="token plain"> H1</span><span class="token punctuation">,</span><span class="token plain"> D_out</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        </span><span class="token triple-quoted-string">&quot;&quot;&quot;</span></span></div><div class="token-line"><span><span class="token triple-quoted-string">        Simple Feedforward with Embeddings</span></span></div><div class="token-line"><span><span class="token triple-quoted-string">        &quot;&quot;&quot;</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        </span><span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token plain">__init__</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    </span><span class="token comment"># user and item embedding layers</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        self</span><span class="token punctuation">.</span><span class="token plain">user_factors </span><span class="token operator">=</span><span class="token plain"> torch</span><span class="token punctuation">.</span><span class="token plain">nn</span><span class="token punctuation">.</span><span class="token plain">Embedding</span><span class="token punctuation">(</span><span class="token plain">n_users</span><span class="token punctuation">,</span><span class="token plain"> n_factors</span><span class="token punctuation">,</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">                                               sparse</span><span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        self</span><span class="token punctuation">.</span><span class="token plain">item_factors </span><span class="token operator">=</span><span class="token plain"> torch</span><span class="token punctuation">.</span><span class="token plain">nn</span><span class="token punctuation">.</span><span class="token plain">Embedding</span><span class="token punctuation">(</span><span class="token plain">n_items</span><span class="token punctuation">,</span><span class="token plain"> n_factors</span><span class="token punctuation">,</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">                                               sparse</span><span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    </span><span class="token comment"># linear layers</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        self</span><span class="token punctuation">.</span><span class="token plain">linear1 </span><span class="token operator">=</span><span class="token plain"> torch</span><span class="token punctuation">.</span><span class="token plain">nn</span><span class="token punctuation">.</span><span class="token plain">Linear</span><span class="token punctuation">(</span><span class="token plain">n_factors</span><span class="token operator">*</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token plain"> H1</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        self</span><span class="token punctuation">.</span><span class="token plain">linear2 </span><span class="token operator">=</span><span class="token plain"> torch</span><span class="token punctuation">.</span><span class="token plain">nn</span><span class="token punctuation">.</span><span class="token plain">Linear</span><span class="token punctuation">(</span><span class="token plain">H1</span><span class="token punctuation">,</span><span class="token plain"> D_out</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    </span><span class="token keyword">def</span><span class="token plain"> </span><span class="token function">forward</span><span class="token punctuation">(</span><span class="token plain">self</span><span class="token punctuation">,</span><span class="token plain"> users</span><span class="token punctuation">,</span><span class="token plain"> items</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        users_embedding </span><span class="token operator">=</span><span class="token plain"> self</span><span class="token punctuation">.</span><span class="token plain">user_factors</span><span class="token punctuation">(</span><span class="token plain">users</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        items_embedding </span><span class="token operator">=</span><span class="token plain"> self</span><span class="token punctuation">.</span><span class="token plain">item_factors</span><span class="token punctuation">(</span><span class="token plain">items</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    </span><span class="token comment"># concatenate user and item embeddings to form input</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        x </span><span class="token operator">=</span><span class="token plain"> torch</span><span class="token punctuation">.</span><span class="token plain">cat</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token plain">users_embedding</span><span class="token punctuation">,</span><span class="token plain"> items_embedding</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token plain"> </span><span class="token number">1</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        h1_relu </span><span class="token operator">=</span><span class="token plain"> F</span><span class="token punctuation">.</span><span class="token plain">relu</span><span class="token punctuation">(</span><span class="token plain">self</span><span class="token punctuation">.</span><span class="token plain">linear1</span><span class="token punctuation">(</span><span class="token plain">x</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        output_scores </span><span class="token operator">=</span><span class="token plain"> self</span><span class="token punctuation">.</span><span class="token plain">linear2</span><span class="token punctuation">(</span><span class="token plain">h1_relu</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        </span><span class="token keyword">return</span><span class="token plain"> output_scores</span></span></div><div class="token-line"><span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    </span><span class="token keyword">def</span><span class="token plain"> </span><span class="token function">predict</span><span class="token punctuation">(</span><span class="token plain">self</span><span class="token punctuation">,</span><span class="token plain"> users</span><span class="token punctuation">,</span><span class="token plain"> items</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        </span><span class="token comment"># return the score</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        output_scores </span><span class="token operator">=</span><span class="token plain"> self</span><span class="token punctuation">.</span><span class="token plain">forward</span><span class="token punctuation">(</span><span class="token plain">users</span><span class="token punctuation">,</span><span class="token plain"> items</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        </span><span class="token keyword">return</span><span class="token plain"> output_scores</span></span></div><div class="token-line"><span><span class="token plain"></span></span></div></pre><div style="position:absolute;left:-1px;top:-1px;height:calc(158.7301587301587% + 2px);width:calc(158.7301587301587% + 2px);transform:scale(0.6300000000000001);transform-origin:left top;border:solid 2px black;pointer-events:none"></div></div></div></div><p>Once again, we train this model on the Movielens dataset with ratings scaled
between <!-- -->[0, 1]<!-- --> to help with convergence. Applied on the test set, we obtain a
root mean-squared error(RMSE) of 0.28, a substantial improvement!</p><h2>Sequence based Recommendation System</h2><p>Finally we build a recommendation system that takes into account the sequence of
item interactions. The heart of this is a Long Short-Term Memory (LSTM) cell, a
variant of Recurrent Neural Networks (RNN) with faster convergence and better
long term memory. The input to this system is a history of item interactions and
their corresponding ratings. In the following example of an input, we show a
sequence of item interaction of length 10 (arbitrarily chosen) and the
corresponding rating. Elements in the first array correspond to items(movies),
and elements in the second array correspond to ratings. We see that, for
example, movie 209 has a rating of 4, and movie 32 has a rating of 5. Sequences
shorter than 10 are padded with zeros.</p><div><div style="position:relative;margin-bottom:25.784999999999997px;width:602px;margin-left:-20.338749999999997px;margin-right:-20.338749999999997px"><div class="prism-code language-python" style="overflow-x:auto;overflow-y:hidden;background:#f3f3f3"><pre style="float:left;font-size:12.892499999999998px;min-width:100%;position:relative;line-height:1.5;margin:0;padding:12.892499999999998px;overflow:visible"><div class="token-line"><span><span class="token plain">In </span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token plain"> training_data</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">Out</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token plain"> </span></span></div><div class="token-line"><span><span class="token plain"></span><span class="token punctuation">(</span><span class="token plain">array</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">209</span><span class="token punctuation">,</span><span class="token plain">  </span><span class="token number">32</span><span class="token punctuation">,</span><span class="token plain"> </span><span class="token number">189</span><span class="token punctuation">,</span><span class="token plain"> </span><span class="token number">242</span><span class="token punctuation">,</span><span class="token plain"> </span><span class="token number">171</span><span class="token punctuation">,</span><span class="token plain"> </span><span class="token number">111</span><span class="token punctuation">,</span><span class="token plain"> </span><span class="token number">256</span><span class="token punctuation">,</span><span class="token plain">   </span><span class="token number">5</span><span class="token punctuation">,</span><span class="token plain">  </span><span class="token number">74</span><span class="token punctuation">,</span><span class="token plain"> </span><span class="token number">102</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token plain"> dtype</span><span class="token operator">=</span><span class="token plain">int32</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain"> array</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token plain"> </span><span class="token number">5</span><span class="token punctuation">,</span><span class="token plain"> </span><span class="token number">3</span><span class="token punctuation">,</span><span class="token plain"> </span><span class="token number">5</span><span class="token punctuation">,</span><span class="token plain"> </span><span class="token number">5</span><span class="token punctuation">,</span><span class="token plain"> </span><span class="token number">5</span><span class="token punctuation">,</span><span class="token plain"> </span><span class="token number">4</span><span class="token punctuation">,</span><span class="token plain"> </span><span class="token number">3</span><span class="token punctuation">,</span><span class="token plain"> </span><span class="token number">1</span><span class="token punctuation">,</span><span class="token plain"> </span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token plain"> dtype</span><span class="token operator">=</span><span class="token plain">int32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain"></span></span></div></pre><div style="position:absolute;left:-1px;top:-1px;height:calc(158.7301587301587% + 2px);width:calc(158.7301587301587% + 2px);transform:scale(0.6300000000000001);transform-origin:left top;border:solid 2px black;pointer-events:none"></div></div></div></div><p>Items are passed through an embedding layer before going into the LSTM. The
output of the LSTM is then fed into a linear layer with an output dimension of
one. The LSTM has 2 hidden states, one for short term memory and one for long
term. Both states need to be initialized.</p><p>PyTorch expects LSTM inputs to be a three dimensional tensor. The first
dimension is the length of the sequence itself, the second represents the number
of instances in a mini-batch, the third is the size of the actual input into the
LSTM. Using our training data example with sequence of length 10 and embedding
dimension of 20, input to the LSTM is a tensor of size 10x1x20 when we do not
use mini batches. For a mini-batch size of 2, each forward pass will have two
sequences, and the input to the LSTM needs to have a dimension of 10x2x20. LSTMs
take variable input sequence lengths but for batch training purposes the input
data is generally processed(with padding if necessary) to have a fixed length.</p><div><div style="position:relative;margin-bottom:25.784999999999997px;width:602px;margin-left:-20.338749999999997px;margin-right:-20.338749999999997px"><div class="prism-code language-python" style="overflow-x:auto;overflow-y:hidden;background:#f3f3f3"><pre style="float:left;font-size:12.892499999999998px;min-width:100%;position:relative;line-height:1.5;margin:0;padding:12.892499999999998px;overflow:visible"><div class="token-line"><span><span class="token keyword">import</span><span class="token plain"> torch</span></span></div><div class="token-line"><span><span class="token plain"></span><span class="token keyword">import</span><span class="token plain"> torch</span><span class="token punctuation">.</span><span class="token plain">nn </span><span class="token keyword">as</span><span class="token plain"> nn</span></span></div><div class="token-line"><span><span class="token plain"></span><span class="token keyword">from</span><span class="token plain"> torch</span><span class="token punctuation">.</span><span class="token plain">autograd </span><span class="token keyword">import</span><span class="token plain"> Variable</span></span></div><div class="token-line"><span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain"></span><span class="token keyword">class</span><span class="token plain"> </span><span class="token class-name">LSTMRating</span><span class="token punctuation">(</span><span class="token plain">nn</span><span class="token punctuation">.</span><span class="token plain">Module</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    </span><span class="token keyword">def</span><span class="token plain"> </span><span class="token function">__init__</span><span class="token punctuation">(</span><span class="token plain">self</span><span class="token punctuation">,</span><span class="token plain"> embedding_dim</span><span class="token punctuation">,</span><span class="token plain"> hidden_dim</span><span class="token punctuation">,</span><span class="token plain"> num_items</span><span class="token punctuation">,</span><span class="token plain"> num_output</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        </span><span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token plain">__init__</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        self</span><span class="token punctuation">.</span><span class="token plain">hidden_dim </span><span class="token operator">=</span><span class="token plain"> hidden_dim</span></span></div><div class="token-line"><span><span class="token plain">        self</span><span class="token punctuation">.</span><span class="token plain">item_embeddings </span><span class="token operator">=</span><span class="token plain"> nn</span><span class="token punctuation">.</span><span class="token plain">Embedding</span><span class="token punctuation">(</span><span class="token plain">num_items</span><span class="token punctuation">,</span><span class="token plain"> embedding_dim</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        self</span><span class="token punctuation">.</span><span class="token plain">lstm </span><span class="token operator">=</span><span class="token plain"> nn</span><span class="token punctuation">.</span><span class="token plain">LSTM</span><span class="token punctuation">(</span><span class="token plain">embedding_dim</span><span class="token punctuation">,</span><span class="token plain"> hidden_dim</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        self</span><span class="token punctuation">.</span><span class="token plain">linear </span><span class="token operator">=</span><span class="token plain"> nn</span><span class="token punctuation">.</span><span class="token plain">Linear</span><span class="token punctuation">(</span><span class="token plain">hidden_dim</span><span class="token punctuation">,</span><span class="token plain"> num_output</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        self</span><span class="token punctuation">.</span><span class="token plain">hidden </span><span class="token operator">=</span><span class="token plain"> self</span><span class="token punctuation">.</span><span class="token plain">init_hidden</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    </span><span class="token keyword">def</span><span class="token plain"> </span><span class="token function">init_hidden</span><span class="token punctuation">(</span><span class="token plain">self</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        </span><span class="token comment"># initialize both hidden layers</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        </span><span class="token keyword">return</span><span class="token plain"> </span><span class="token punctuation">(</span><span class="token plain">Variable</span><span class="token punctuation">(</span><span class="token plain">torch</span><span class="token punctuation">.</span><span class="token plain">zeros</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token plain"> </span><span class="token number">1</span><span class="token punctuation">,</span><span class="token plain"> self</span><span class="token punctuation">.</span><span class="token plain">hidden_dim</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">                Variable</span><span class="token punctuation">(</span><span class="token plain">torch</span><span class="token punctuation">.</span><span class="token plain">zeros</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token plain"> </span><span class="token number">1</span><span class="token punctuation">,</span><span class="token plain"> self</span><span class="token punctuation">.</span><span class="token plain">hidden_dim</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    </span><span class="token keyword">def</span><span class="token plain"> </span><span class="token function">forward</span><span class="token punctuation">(</span><span class="token plain">self</span><span class="token punctuation">,</span><span class="token plain"> sequence</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        embeddings </span><span class="token operator">=</span><span class="token plain"> self</span><span class="token punctuation">.</span><span class="token plain">item_embeddings</span><span class="token punctuation">(</span><span class="token plain">sequence</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        output</span><span class="token punctuation">,</span><span class="token plain"> self</span><span class="token punctuation">.</span><span class="token plain">hidden </span><span class="token operator">=</span><span class="token plain"> self</span><span class="token punctuation">.</span><span class="token plain">lstm</span><span class="token punctuation">(</span><span class="token plain">embeddings</span><span class="token punctuation">.</span><span class="token plain">view</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span><span class="token plain">sequence</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token plain"> </span><span class="token number">1</span><span class="token punctuation">,</span><span class="token plain"> </span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">                                        self</span><span class="token punctuation">.</span><span class="token plain">hidden</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        rating_scores </span><span class="token operator">=</span><span class="token plain"> self</span><span class="token punctuation">.</span><span class="token plain">linear</span><span class="token punctuation">(</span><span class="token plain">output</span><span class="token punctuation">.</span><span class="token plain">view</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span><span class="token plain">sequence</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token plain"> </span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        </span><span class="token keyword">return</span><span class="token plain"> rating_scores</span></span></div><div class="token-line"><span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    </span><span class="token keyword">def</span><span class="token plain"> </span><span class="token function">predict</span><span class="token punctuation">(</span><span class="token plain">self</span><span class="token punctuation">,</span><span class="token plain"> sequence</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        rating_scores </span><span class="token operator">=</span><span class="token plain"> self</span><span class="token punctuation">.</span><span class="token plain">forward</span><span class="token punctuation">(</span><span class="token plain">sequence</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">        </span><span class="token keyword">return</span><span class="token plain"> rating_scores</span></span></div><div class="token-line"><span><span class="token plain"></span></span></div></pre><div style="position:absolute;left:-1px;top:-1px;height:calc(158.7301587301587% + 2px);width:calc(158.7301587301587% + 2px);transform:scale(0.6300000000000001);transform-origin:left top;border:solid 2px black;pointer-events:none"></div></div></div></div><p>Once the neural network is defined, we fit the training data using stochastic
gradient descent with a mean squared error loss function. </p><div><div style="position:relative;margin-bottom:25.784999999999997px;width:602px;margin-left:-20.338749999999997px;margin-right:-20.338749999999997px"><div class="prism-code language-python" style="overflow-x:auto;overflow-y:hidden;background:#f3f3f3"><pre style="float:left;font-size:12.892499999999998px;min-width:100%;position:relative;line-height:1.5;margin:0;padding:12.892499999999998px;overflow:visible"><div class="token-line"><span><span class="token plain">embedding_dim </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">64</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">hidden_dim </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">128</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">n_output </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">1</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain"></span><span class="token comment"># add one to represent padding when there is not enough history</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">model </span><span class="token operator">=</span><span class="token plain"> LSTMRating</span><span class="token punctuation">(</span><span class="token plain">embedding_dim</span><span class="token punctuation">,</span><span class="token plain"> hidden_dim</span><span class="token punctuation">,</span><span class="token plain"> n_items</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token plain"> n_output</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">loss_fn </span><span class="token operator">=</span><span class="token plain"> nn</span><span class="token punctuation">.</span><span class="token plain">MSELoss</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">optimizer </span><span class="token operator">=</span><span class="token plain"> optim</span><span class="token punctuation">.</span><span class="token plain">SGD</span><span class="token punctuation">(</span><span class="token plain">model</span><span class="token punctuation">.</span><span class="token plain">parameters</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token plain"> lr</span><span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain"></span><span class="token keyword">for</span><span class="token plain"> sequence</span><span class="token punctuation">,</span><span class="token plain"> target_ratings </span><span class="token keyword">in</span><span class="token plain"> training_data</span><span class="token punctuation">:</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    model</span><span class="token punctuation">.</span><span class="token plain">zero_grad</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    </span><span class="token comment"># initialize hidden layers</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    model</span><span class="token punctuation">.</span><span class="token plain">hidden </span><span class="token operator">=</span><span class="token plain"> model</span><span class="token punctuation">.</span><span class="token plain">init_hidden</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    </span><span class="token comment"># convert sequence to PyTorch variables</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    sequence_var </span><span class="token operator">=</span><span class="token plain"> Variable</span><span class="token punctuation">(</span><span class="token plain">torch</span><span class="token punctuation">.</span><span class="token plain">LongTensor</span><span class="token punctuation">(</span><span class="token plain">sequence</span><span class="token punctuation">.</span><span class="token plain">astype</span><span class="token punctuation">(</span><span class="token string">&#x27;int64&#x27;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    </span><span class="token comment"># forward pass</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    ratings_scores </span><span class="token operator">=</span><span class="token plain"> model</span><span class="token punctuation">(</span><span class="token plain">sequence_var</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    target_ratings_var </span><span class="token operator">=</span><span class="token plain"> Variable</span><span class="token punctuation">(</span><span class="token plain">torch</span><span class="token punctuation">.</span><span class="token plain">FloatTensor</span><span class="token punctuation">(</span><span class="token plain">target_ratings</span><span class="token punctuation">.</span><span class="token plain">astype</span><span class="token punctuation">(</span><span class="token string">&#x27;float32&#x27;</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    </span><span class="token comment"># compute loss</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    loss </span><span class="token operator">=</span><span class="token plain"> loss_fn</span><span class="token punctuation">(</span><span class="token plain">ratings_scores</span><span class="token punctuation">,</span><span class="token plain"> target_ratings_var</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    </span><span class="token comment"># backpropagate</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    loss</span><span class="token punctuation">.</span><span class="token plain">backward</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    </span><span class="token comment"># update weights</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain">    optimizer</span><span class="token punctuation">.</span><span class="token plain">step</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token plain"></span></span></div><div class="token-line"><span><span class="token plain"></span></span></div></pre><div style="position:absolute;left:-1px;top:-1px;height:calc(158.7301587301587% + 2px);width:calc(158.7301587301587% + 2px);transform:scale(0.6300000000000001);transform-origin:left top;border:solid 2px black;pointer-events:none"></div></div></div></div><p>Similar to other models, we train the LSTM-based model on the Movielens dataset
with ratings scaled between <!-- -->[0, 1]<!-- --> to help with convergence. Applied on the test
set, we obtain a root mean-squared error(RMSE) of 0.43 - the LSTM model
underperforms the dense feed forward network.</p><h2>Post-amble</h2><p>The models discussed in this post are basic building blocks for a recommendation
system in PyTorch. There are no bells and whistles and we did not attempt to
fine tune any hyperparameters. Our first pass result suggests that the dense
network performs best, followed by the LSTM network and finally the matrix
factorization model. The root mean-squared error (RMSE) are 0.28, 0.43 and 0.66
respectively on the Movielens 100K dataset with ratings scaled between <!-- -->[0,
1]<!-- -->. We thought PyTorch was fun to use; models can be built and swapped out
relatively easily. When we did encounter errors, most of them were triggered by
incorrect data types.</p><p>For more on recommendations, please see our <a href="https://www.cloudera.com/more/services-and-support/fast-forward-labs.html">Semantic Recommendations report</a>
where we focus on how machines can better understand content!</p><div style="display:none;justify-content:center;padding:12.892499999999998px" class="jsx-1135431938 jsx-2959859206"><img style="height:18.75272727272727px;width:18.75272727272727px;position:relative;display:block" src="/static/images/ff.png" class="jsx-1135431938 jsx-2959859206"/></div></div></div></div><div style="position:relative;display:block;width:612.8924999999999px;grid-template-columns:repeat(2, 1fr);margin-left:-12.892499999999998px;margin-right:-12.892499999999998px"><div style="display:grid"><div style="position:relative;display:grid;grid-template-rows:auto 1fr;margin-bottom:12.892499999999998px"><div style="text-transform:uppercase;font-size:12.892499999999998px;letter-spacing:0.03em;line-height:1.5;padding-bottom:6.446249999999999px;padding-left:25.784999999999997px">Newer</div><div style="position:relative;display:grid"><a class="hover-box no-underline no-hover gray-backer hover-extend" style="display:block;position:relative;width:612.8925px;padding-left:12.892499999999998px;padding-right:12.892499999999998px;margin-left:0;margin-right:0" href="/2018/04/18/introducing-scifi.html"><div style="display:flex;flex-wrap:wrap"><div style="display:flex;width:587.1075px;font-size:12.892499999999998px;letter-spacing:0.03em;text-transform:uppercase;line-height:1.5;margin-left:0"><div style="width:293.55375px;padding:12.892499999999998px 12.892499999999998px 0px 12.892499999999998px"><div>Apr 05 2018</div></div><div style="width:293.55375px;padding:12.892499999999998px 12.892499999999998px 0px 12.892499999999998px"><div>post</div></div></div><div style="position:relative;width:587.1075px;padding:12.892499999999998px 0px"><div style="font-size:25.784999999999997px;line-height:1.25;padding:0px 12.892499999999998px;margin-top:-6.446249999999999px"><div style="padding-left:0">Introducing SciFi</div></div><div style="padding-top:6.446249999999999px;position:relative"><div style="font-size:15.041249999999998px;line-height:1.5em;display:flex;flex-wrap:wrap;padding-left:0"><div style="padding:0px 12.892499999999998px;width:293.55375px"><div style="height:90.24749999999999px;overflow:hidden;display:-webkit-box;-webkit-line-clamp:4;hyphens:auto;-webkit-box-orient:vertical"><span>by <!-- -->Grant<!-- --> â—¦ </span>
Today we are launching a mini-site featuring our collection of short stories inspired by new developments in machine learning.   Beginning with our fourth report, we started including a science-fiction story along with the technical and strategic overviews that are the bulk of...</div><div style="overflow:hidden;width:100%;text-overflow:ellipsis;white-space:nowrap"><span class="display-link"><span>View<!-- --> <span style="text-transform:lowercase">post</span></span></span></div></div><div style="position:relative;width:293.55375px"><div style="width:calc(100% - 25.784999999999997px);height:calc(100% - 12.892499999999998px);margin-left:12.892499999999998px;margin-top:6.446249999999999px;background-image:url(/static/images/editor_uploads/2018-04-19-185324-scifi_crop.png);background-size:contain;background-position:center center;background-repeat:no-repeat"></div></div></div></div></div></div></a><div style="position:absolute;left:-1px;top:-1px;height:calc(158.7301587301587% + 2px);width:calc(158.7301587301587% + 2px);transform:scale(0.6300000000000001);transform-origin:left top;border:solid 2px black;pointer-events:none"></div></div></div></div><div style="display:grid"><div style="position:relative;display:grid;grid-template-rows:auto 1fr;margin-bottom:12.892499999999998px"><div style="text-transform:uppercase;font-size:12.892499999999998px;letter-spacing:0.03em;line-height:1.5;padding-bottom:6.446249999999999px;padding-left:25.784999999999997px">Older</div><div style="position:relative;display:grid"><a class="hover-box no-underline no-hover gray-backer hover-extend" style="display:block;position:relative;width:612.8925px;padding-left:12.892499999999998px;padding-right:12.892499999999998px;margin-left:0;margin-right:0" href="/2018/03/28/unemployment-vs-augmentation.html"><div style="display:flex;flex-wrap:wrap"><div style="display:flex;width:587.1075px;font-size:12.892499999999998px;letter-spacing:0.03em;text-transform:uppercase;line-height:1.5;margin-left:0"><div style="width:293.55375px;padding:12.892499999999998px 12.892499999999998px 0px 12.892499999999998px"><div>Mar 04 2018</div></div><div style="width:293.55375px;padding:12.892499999999998px 12.892499999999998px 0px 12.892499999999998px"><div>Newsletter</div></div></div><div style="position:relative;width:587.1075px;padding:12.892499999999998px 0px"><div style="font-size:25.784999999999997px;line-height:1.25;padding:0px 12.892499999999998px;margin-top:-6.446249999999999px"><div style="padding-left:0">Unemployment vs. Augmentation</div></div><div style="padding-top:6.446249999999999px;position:relative"><div style="font-size:15.041249999999998px;line-height:1.5em;display:flex;flex-wrap:wrap;padding-left:0"><div style="padding:0px 12.892499999999998px;width:293.55375px"><div style="height:90.24749999999999px;overflow:hidden;display:-webkit-box;-webkit-line-clamp:4;hyphens:auto;-webkit-box-orient:vertical">
In the ongoing debates around whether or not robots are going to take our jobs, listening to those who have a real stake in the technology is critical, and often offers important insights for how we build new technologies, as well as how we talk about what we build. Take, for...</div><div style="overflow:hidden;width:100%;text-overflow:ellipsis;white-space:nowrap"><span class="display-link"><span>View<!-- --> <span style="text-transform:lowercase">Newsletter</span></span></span></div></div><div style="position:relative;width:293.55375px"><div style="width:calc(100% - 25.784999999999997px);height:calc(100% - 12.892499999999998px);margin-left:12.892499999999998px;margin-top:6.446249999999999px;background-image:url(/static/images/2018/02/1_ruUDqwD4sGZOhIkeK2zUYQ-1519759204276.png);background-size:contain;background-position:center center;background-repeat:no-repeat"></div></div></div></div></div></div></a><div style="position:absolute;left:-1px;top:-1px;height:calc(158.7301587301587% + 2px);width:calc(158.7301587301587% + 2px);transform:scale(0.6300000000000001);transform-origin:left top;border:solid 2px black;pointer-events:none"></div></div></div></div></div><div style="padding-bottom:25.784999999999997px;padding-top:25.784999999999997px" class="jsx-1135431938 jsx-2959859206"><div style="font-size:34.379999999999995px;line-height:1.25;padding:0px 12.892499999999998px 0px 12.892499999999998px;margin-bottom:12.892499999999998px;width:587.1075px;margin-left:0" class="jsx-1135431938 jsx-2959859206">About</div><div style="padding:0px 12.892499999999998px;margin-bottom:12.892499999999998px;width:587.1075px;margin-left:0;font-size:17.189999999999998px;line-height:1.5" class="jsx-1135431938 jsx-2959859206">Cloudera Fast Forward Labs is an applied machine learning research group. We help organizations recognize and develop new product and business opportunities through emerging technologies.<!-- --> </div><div style="padding:0px 12.892499999999998px;margin-bottom:12.892499999999998px;width:587.1075px;margin-left:0;font-size:17.189999999999998px;line-height:1.5" class="jsx-1135431938 jsx-2959859206"><a href="https://www.cloudera.com/products/fast-forward-labs-research.html" class="jsx-1135431938 jsx-2959859206">Learn more about working with us.</a></div></div></div><div class="jsx-1135431938 jsx-2959859206"><div style="position:relative" class="jsx-1135431938 jsx-2959859206"><div style="position:absolute;left:0;width:100%;height:2px;transform:scaleY(0.60165);transform-origin:center center;background:black;top:-1px"></div><div style="padding:12.892499999999998px;display:flex;justify-content:space-between;flex-wrap:wrap;font-size:17.189999999999998px;line-height:1.5" class="jsx-1135431938 jsx-2959859206"><div class="jsx-1135431938 jsx-2959859206"><a href="/" class="jsx-1135431938 jsx-2959859206">Blog</a></div><div style="display:flex;flex-wrap:wrap" class="jsx-1135431938 jsx-2959859206"><div style="margin-right:12.892499999999998px" class="jsx-1135431938 jsx-2959859206"><a href="https://www.cloudera.com/products/fast-forward-labs-research.html" class="jsx-1135431938 jsx-2959859206">Cloudera</a></div><div style="margin-right:12.892499999999998px" class="jsx-1135431938 jsx-2959859206"><a href="https://blog.fastforwardlabs.com/" class="jsx-1135431938 jsx-2959859206">AI Experiments</a></div><div class="jsx-1135431938 jsx-2959859206"><a href="https://twitter.com/fastforwardlabs" class="jsx-1135431938 jsx-2959859206">Twitter</a></div></div></div></div></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{}},"page":"/posts/2018-04-10-pytorch-for-recommenders-101","query":{},"buildId":"EnU~FBvqy_55fWO5RkIyH","nextExport":true}</script><script async="" id="__NEXT_PAGE__/posts/2018-04-10-pytorch-for-recommenders-101" src="/_next/static/EnU~FBvqy_55fWO5RkIyH/pages/posts/2018-04-10-pytorch-for-recommenders-101.js"></script><script async="" id="__NEXT_PAGE__/_app" src="/_next/static/EnU~FBvqy_55fWO5RkIyH/pages/_app.js"></script><script src="/_next/static/runtime/webpack-fdce77a122c11e06ae50.js" async=""></script><script src="/_next/static/chunks/commons.f77b50de979bfbbb280b.js" async=""></script><script src="/_next/static/runtime/main-5ab107747766f1b4e0bf.js" async=""></script></body></html>