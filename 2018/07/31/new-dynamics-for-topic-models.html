<!DOCTYPE html><html><head><link rel="preload" href="/static/fonts/Inter-Regular.woff2?v=3.5" as="font" type="font/woff2" crossorigin="*"/><link rel="preload" href="/static/fonts/Inter-Italic.woff2?v=3.5" as="font" type="font/woff2" crossorigin="*"/><link href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css" rel="stylesheet"/><meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1" class="next-head"/><meta charSet="utf-8" class="next-head"/><style class="next-head">.js-no-flash { display: none }</style><noscript class="jsx-4059783939 jsx-3344216300 next-head"><style>.js-no-flash { display: block }</style></noscript><link rel="icon" type="image/x-icon" href="static/images/favicon.png" class="jsx-1135431938 jsx-2959859206 next-head"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous" class="jsx-1135431938 jsx-2959859206 next-head"/><title class="jsx-1135431938 jsx-2959859206 next-head">New Dynamics for Topic Models - Cloudera Fast Forward</title><link rel="preload" href="/_next/static/Ybc3fb3eGTaHFGC_lgzB6/pages/posts/2018-07-31-new-dynamics-for-topic-models.js" as="script"/><link rel="preload" href="/_next/static/Ybc3fb3eGTaHFGC_lgzB6/pages/_app.js" as="script"/><link rel="preload" href="/_next/static/runtime/webpack-fdce77a122c11e06ae50.js" as="script"/><link rel="preload" href="/_next/static/chunks/commons.f77b50de979bfbbb280b.js" as="script"/><link rel="preload" href="/_next/static/runtime/main-5ab107747766f1b4e0bf.js" as="script"/><style id="__jsx-4059783939">@font-face{font-family:'Inter';font-style:normal;font-weight:400;src:url('/static/fonts/Inter-Regular.woff2?v=3.5') format('woff2'), url('/static/fonts/Inter-Regular.woff?v=3.5') format('woff');}@font-face{font-family:'Inter';font-style:italic;font-weight:400;src:url('/static/fonts/Inter-Italic.woff2?v=3.5') format('woff2'), url('/static/fonts/Inter-Italic.woff?v=3.5') format('woff');}@font-face{font-family:'Inter';font-style:normal;font-weight:700;src:url('/static/fonts/Inter-Bold.woff2?v=3.5') format('woff2'), url('/static/fonts/Inter-Bold.woff?v=3.5') format('woff');}@font-face{font-family:'Inter';font-style:italic;font-weight:700;src:url('/static/fonts/Inter-BoldItalic.woff2?v=3.5') format('woff2'), url('/static/fonts/Inter-BoldItalic.woff?v=3.5') format('woff');}*{box-sizing:border-box;}html{font-family:'Inter',serif;font-size:18px;line-height:27px;text-rendering:optimizelegibility;font-feature-settings:'kern';font-kerning:normal;font-feature-settings:'ss02' 1;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;}pre{-webkit-font-smoothing:auto;-moz-osx-font-smoothing:auto;overflow-x:auto;font-family:SFMono-Regular,Consolas,Liberation Mono,Menlo, Monaco,Courier New,monospace;}body{margin:0;overflow-x:hidden;}a{color:inherit;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:opacity 0.025s linear;transition:opacity 0.025s linear;}a:hover{opacity:0.75;}a.no-hover:hover{opacity:1;}.hover_box_overlay{opacity:0;-webkit-transition:opacity 0.025s linear;transition:opacity 0.025s linear;}.hover_box:hover .hover_box_overlay{opacity:1;}a.gray-backer{-webkit-transition:background 0.05s linear;transition:background 0.05s linear;}a.gray-backer:hover{background:#f3f3f3;}button:focus{outline:#999 auto 3px;}</style><style id="__jsx-3344216300">html{font-size:17.189999999999998px;line-height:25.784999999999997px;}a,.display-link{background-image:linear-gradient( to right, black 100%, transparent 0% );background-position:0em calc(1.07em);background-repeat:repeat-x;background-size:1em 0.07em;}a.no-underline{background-image:none;}a.no-hover{background-image:none;}a.no-hover:hover{background-image:none;opacity:1;}</style><style id="__jsx-2959859206">h1,h2,h3,h4,h5,h6{font-weight:400;font-style:normal;margin:0;}h1{font-size:51.56999999999999px;line-height:1.25;}h2{font-size:34.379999999999995px;line-height:1.25;padding-top:25.784999999999997px;margin-bottom:25.784999999999997px;}h3{font-size:25.784999999999997px;line-height:1.25;padding-top:25.784999999999997px;margin-bottom:25.784999999999997px;}h4{font-size:21.487499999999997px;line-height:1.25;padding-top:0px;margin-bottom:25.784999999999997px;}h5{font-size:12.892499999999998px;line-height:1.4375;margin-bottom:12.892499999999998px;padding-bottom:12.892499999999998px;margin-top:-12.892499999999998px;}p{margin:0 0 25.784999999999997px 0;}ol,ul{margin:0 0 25.784999999999997px 0;padding-left:25.784999999999997px;}blockquote{margin:0 0 25.784999999999997px 25.784999999999997px;}.html-video-holder{margin:0 0 25.784999999999997px 0;}video{max-width:100%;}code{background:#eaeaea;padding-right:3px;padding-left:3px;font-size:0.975em;word-break:break-word;}</style><style id="__jsx-1135431938">code[class*='language-'],pre[class*='language-']{color:black;background:none;font-family:Consolas,Monaco,'Andale Mono','Ubuntu Mono', monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;}pre[class*='language-']::-moz-selection,pre[class*='language-']::-moz-selection,code[class*='language-']::-moz-selection,code[class*='language-']::-moz-selection{text-shadow:none;}pre[class*='language-']::selection,pre[class*='language-']::selection,code[class*='language-']::selection,code[class*='language-']::selection{text-shadow:none;}@media print{code[class*='language-'],pre[class*='language-']{text-shadow:none;}}:not(pre)>code[class*='language-']{white-space:normal;}.token.comment,.token.prolog,.token.doctype,.token.cdata{color:slategray;}.token.punctuation{color:#999;}.namespace{opacity:0.7;}.token.property,.token.tag,.token.boolean,.token.number,.token.constant,.token.symbol,.token.deleted{color:#905;}.token.selector,.token.attr-name,.token.string,.token.char,.token.builtin,.token.inserted{color:#690;}.token.operator,.token.entity,.token.url,.language-css .token.string,.style .token.string{color:#9a6e3a;}.token.atrule,.token.attr-value,.token.keyword{color:#07a;}.token.function,.token.class-name{color:#dd4a68;}.token.regex,.token.important,.token.variable{color:#e90;}.token.important,.token.bold{font-weight:bold;}.token.italic{font-style:italic;}.token.entity{cursor:help;}</style></head><body><div id="__next"><div class="jsx-4059783939 jsx-3344216300 js-no-flash"><div style="padding-bottom:12.892499999999998px"><div style="position:relative"><div style="position:relative;padding:6.446249999999999px 12.892499999999998px 6.446249999999999px 12.892499999999998px;background-image:url(&quot;/static/images/dataline.png&quot;)"><div style="display:flex;justify-content:space-between"><div style="display:flex;align-items:center;height:25.784999999999997px;padding-top:1px"><a href="https://www.cloudera.com/products/fast-forward-labs-research.html" style="display:block;line-height:0" class="no-underline no-hover"><img style="height:12.892499999999998px" src="/static/images/cloudera.png"/></a></div><div style="display:flex;align-items:center;padding-top:1px;font-size:17.189999999999998px;line-height:1.5"><a class="no-underline" href="https://www.cloudera.com/products/fast-forward-labs-research.html" style="color:#333e47;font-size:12.892499999999998px;line-height:1.5">About Us →</a></div></div><div style="position:absolute;left:0;width:100%;height:2px;transform:scaleY(0.60165);transform-origin:center center;background:rgba(0,0,0,0.125);bottom:-1px"></div></div><div style="padding:12.892499999999998px 12.892499999999998px 12.892499999999998px 12.892499999999998px;display:flex;justify-content:space-between;font-size:17.189999999999998px;line-height:1.5"><div style="display:flex;align-items:center"><a class="no-hover no-underline" style="display:flex;align-items:center" href="/"><img style="height:18.75272727272727px;width:18.75272727272727px;margin-right:9.669374999999999px;position:relative;top:-0.5860227272727272px" src="/static/images/ff.png"/><div>Fast Forward Labs </div></a></div><div style="display:flex;align-items:center;height:25.784999999999997px"></div><div style="display:flex"><div style="margin-right:12.892499999999998px"><a href="/">Blog</a></div><div><a href="https://experiments.fastforwardlabs.com">AI Experiments</a></div></div></div><div style="position:absolute;left:0;width:100%;height:2px;transform:scaleY(0.60165);transform-origin:center center;background:black;bottom:-1px"></div></div></div><div class="jsx-1135431938 jsx-2959859206"><div style="position:relative" class="jsx-1135431938 jsx-2959859206"><div style="padding-left:6.446249999999999px;padding-right:6.446249999999999px;padding-top:25.784999999999997px" class="jsx-1135431938 jsx-2959859206"><div class="jsx-1135431938 jsx-2959859206"><div style="display:flex;margin-bottom:12.892499999999998px;width:587.1075px;margin-left:0" class="jsx-1135431938 jsx-2959859206"><div style="width:293.55375px;padding:0px 12.892499999999998px;position:relative;font-size:12.892499999999998px;letter-spacing:0.03em;text-transform:uppercase;line-height:1" class="jsx-1135431938 jsx-2959859206">Jul 03 2018</div><div style="width:293.55375px;padding:0px 12.892499999999998px;position:relative;font-size:12.892499999999998px;letter-spacing:0.03em;text-transform:uppercase;line-height:1" class="jsx-1135431938 jsx-2959859206">Newsletter</div></div><div style="margin-bottom:0" class="jsx-1135431938 jsx-2959859206"><div style="font-size:42.974999999999994px;line-height:1.25;padding:0px 12.892499999999998px;width:587.1075px;margin-left:0" class="jsx-1135431938 jsx-2959859206">New Dynamics for Topic Models</div></div><div style="display:flex;flex-wrap:wrap;width:587.1075px;margin-left:0" class="jsx-1135431938 jsx-2959859206"><div style="width:587.1075px;padding:25.784999999999997px 12.892499999999998px 25.784999999999997px 12.892499999999998px" class="jsx-1135431938 jsx-2959859206"><p>Topic models can extract key themes from large collections of documents in an unsupervised manner, which makes them one of the most powerful tools in organizing, searching, and understanding the vast troves of text data produced by humanity. Their power derives, in part, from their in-built assumptions about the nature of text; specifically, to identify topics, the model has to give the notion of a topic a mathematical structure that echoes its significance to a human reader. In their recent paper, <a href="https://arxiv.org/abs/1803.07868"><em>Scalable Generalized Dynamic Topic Models</em></a>, Patrick Jähnichen, Florian Wenzel, Marius Kloft, and Stephan Mandt show scalable models that allow topics to change over time in a way that is more general than it was previously, extracting new forms of patterns from large-scale datasets.</p><h2>Probabilistic Topic Models: from Static to Dynamic</h2><p>Jähnchen et al.&#x27;s work builds on the shift towards probabilistic topic models that was cemented by the publication of David Blei, Andrew Ng, and Michael Jordan’s seminal <a href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation"><em>Latent Dirichlet Allocation (LDA)</em></a> in 2003. The context, at the time, was given in particular by <a href="http://lsa.colorado.edu/papers/JASIS.lsi.90.pdf"><em>Latent Semantic Indexing (LSI)</em></a> (1990), which relies on finding linear combinations of <a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf"><em>tf-idf</em></a> features that explain the greatest amount of variation in a corpus. Topics, in that case, are then weighted collections of words that are particularly discriminative with respect to identifying individual documents in the corpus, and finding them requires the singular value decomposition of a document matrix.</p><p>In contrast, <a href="https://cacm.acm.org/magazines/2012/4/147361-probabilistic-topic-models/fulltext#F1">probabilistic topic models</a> rely on reverse engineering an imagined statistical process that generates the documents, in which the topics are latent parameters that are inferred from the raw corpus data. The generative process for LDA, for example, is a hierarchical Bayesian model that assumes that each word within a document is drawn from one of several multinomial distributions that correspond to topics. The mixture of topics in each document, i.e. the probability with which one of the multinomial distributions will give rise to a word in the document, is in turn determined by drawing from a Dirichlet distribution. Writing this out results in an intractable expression for the probability of each word, which is conditional on the topic parameters and can be fitted to the corpus using a host of well-known methods (as well as, conveniently, packages like <a href="https://radimrehurek.com/gensim/models/ldamodel.html">gensim</a> and <a href="http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#sklearn.decomposition.LatentDirichletAllocation">sklearn</a>).</p><p>Of course, the inference process is considerably more difficult than the linear algebra required of LSI, but the process of designing a generative process makes it possible to imbue the topics with properties that highlight aspects of interest, or that make the topic model more realistic. For example, one might allow for topics to be correlated in the way that they co-occur within a document. At the expense of having to fit additional parameters, this enables surfacing <a href="http://people.ee.duke.edu/~lcarin/Blei2005CTM.pdf">topic relationships</a>.</p><p>With <a href="https://mimno.infosci.cornell.edu/info6150/readings/dynamic_topic_models.pdf">Dynamic Topic Models</a> (2006), David Blei and John Lafferty revisited the LDA process to tackle the problem of topics changing over time. While the original LDA model ignores any ordering of the documents in the corpus, dynamic topic models will take their time stamps into account. Blei and Lafferty did so by allowing the topic parameters to wander over time, specifically by imposing upon them a <a href="https://en.wikipedia.org/wiki/Wiener_process">Wiener Process</a>, also known as Brownian Motion. The results are highly compelling: in their <a href="https://mimno.infosci.cornell.edu/info6150/readings/dynamic_topic_models.pdf">paper</a>, they analyze over a century of <em>Science</em> magazine articles, and automatically extract a small history of neuroscience and atomic physics. (Blei happens to be an excellent lecturer, and those looking for his talks online will find a more <a href="https://www.youtube.com/watch?v=FkckgwMHP2s">comfortable introduction</a> to ideas in topic modeling than is provided by the technical papers.)</p><p><div style="position:relative"><img src="/static/images/2018/07/f5-1531838383022.jpg" style="display:block;margin:0;width:100%"/></div></p><h5>Time Evolution of two topics within the Science corpus. From: <a href="https://deliveryimages.acm.org/10.1145/2140000/2133826/figs/f5.jpg">D. Blei, Probabilistic Topic Models, Communications of the ACM (2012)</a></h5><h2>Scalable New Dynamics</h2><p>A Wiener process is convenient in several ways. It describes a random walk in which the value after each time step is simply the last time step, plus a random increment that is drawn from a normal distribution. In case of the LDA topic model, this allows for the multinomial distributions that represent the topics to undergo an incremental drift. In this way, the topics can change, albeit slowly enough to draw statistical robustness from older document data. The simplicity of the Wiener process also introduces temporal dynamics with the minimum number of additional parameters, and, given the difficulty of performing scalable approximate inference on topic models that implement dynamical stochastic process priors, had so far been the only process for which inference was feasible.</p><p>Jähnchen and colleagues now managed to substantially extend the spectrum of time dynamics to the general class of <a href="https://en.wikipedia.org/wiki/Gaussian_process">Gaussian Processes</a>, of which the Wiener process is the simplest subcase. Gaussian processes are completely defined by their mean and covariance function in the same way in which a Gaussian distribution is completely defined by mean and variance, and just like the Gaussian distribution, they simultaneously represent the simplest interesting case and are extremely broadly applicable. In <a href="https://arxiv.org/abs/1803.07868">the study</a>, the authors proceed by exploring the new wealth of possible functions by implementing dynamic topic models based on a three common processes used in time series modeling, comparing each to the result based on the Wiener process. The processes, which represent a small subset of realizable properties, include:</p><h3>1. Ornstein-Uhlenbeck:</h3><p>Brownian motion in the presence of a mean reverting force (in physics, this would for example occur for a spring that is undergoing thermal noise).</p><h3>2. Squared Exponential kernel:</h3><p>A process with a memory over several previous time steps, in which the correlation with past time steps decreases exponentially. That is, the process has a short-term memory that can be tuned by changing the decay length.</p><h3>3. Cauchy kernel:</h3><p>A process that has memory, similar to the one that corresponds to the squared exponential kernel, but in this case, the correlation with past time steps decreases polynomially. The process has a long-term memory.</p><p>Based on large scale datasets, the authors reveal that each of these approaches reveals qualitatively different phenomena, and conclude that they offer better performance along the lines of interpretability and usefulness, as well as perplexity measures. However, the greatest strength is likely the ability to flexibly experiment with different types of processes toward different tasks: processes with short-term memory can be used for event detection, whereas long-term memory has greater statistical strength. The mean-reversion property acts as a type of regularization that responds to small-scale changes and localized topics in time. Adding and multiplying kernels also results in valid kernels, enabling considerable fine tuning. While deferred to future work, periodic kernels should be able to detect recurring events.</p><p>On the whole, playing with different processes enables practitioners to intuitively adapt and experiment with dynamic topic models to analyze time-stamped corpora in a targeted way, benefiting from the extensive experience that has been gathered by studying time series in general. Apart from growing in sophistication, topic models will also grow in diversity: as the authors indicated toward the conclusion of the paper, the selection of a prior is a modeling choice that helps reveal the effects that one searches for.</p><div style="display:none;justify-content:center;padding:12.892499999999998px" class="jsx-1135431938 jsx-2959859206"><img style="height:18.75272727272727px;width:18.75272727272727px;position:relative;display:block" src="/static/images/ff.png" class="jsx-1135431938 jsx-2959859206"/></div></div></div></div><div style="position:relative;display:block;width:612.8924999999999px;grid-template-columns:repeat(2, 1fr);margin-left:-12.892499999999998px;margin-right:-12.892499999999998px"><div style="display:grid"><div style="position:relative;display:grid;grid-template-rows:auto 1fr;margin-bottom:12.892499999999998px"><div style="text-transform:uppercase;font-size:12.892499999999998px;letter-spacing:0.03em;line-height:1.5;padding-bottom:6.446249999999999px;padding-left:25.784999999999997px">Newer</div><div style="position:relative;display:grid"><a class="hover-box no-underline no-hover gray-backer hover-extend" style="display:block;position:relative;width:612.8925px;padding-left:12.892499999999998px;padding-right:12.892499999999998px;margin-left:0;margin-right:0" href="/2018/07/31/progress-in-machine-learning-interpretability.html"><div style="display:flex;flex-wrap:wrap"><div style="display:flex;width:587.1075px;font-size:12.892499999999998px;letter-spacing:0.03em;text-transform:uppercase;line-height:1.5;margin-left:0"><div style="width:293.55375px;padding:12.892499999999998px 12.892499999999998px 0px 12.892499999999998px"><div>Jul 03 2018</div></div><div style="width:293.55375px;padding:12.892499999999998px 12.892499999999998px 0px 12.892499999999998px"><div>Newsletter</div></div></div><div style="position:relative;width:587.1075px;padding:12.892499999999998px 0px"><div style="font-size:25.784999999999997px;line-height:1.25;padding:0px 12.892499999999998px;margin-top:-6.446249999999999px"><div style="padding-left:0">Progress in machine learning interpretability</div></div><div style="padding-top:6.446249999999999px;position:relative"><div style="font-size:15.041249999999998px;line-height:1.5em;display:flex;flex-wrap:wrap;padding-left:0"><div style="padding:0px 12.892499999999998px;width:293.55375px"><div style="height:90.24749999999999px;overflow:hidden;display:-webkit-box;-webkit-line-clamp:4;hyphens:auto;-webkit-box-orient:vertical">
Our goal when we do research is to address capabilities and technologies that
we expect to become production-ready in one to two years. That focus on
fast-moving areas means that new algorithmic ideas sometimes come along that
allow our clients to extend or improve upon the work...</div><div style="overflow:hidden;width:100%;text-overflow:ellipsis;white-space:nowrap"><span class="display-link"><span>View<!-- --> <span style="text-transform:lowercase">Newsletter</span></span></span></div></div><div style="position:relative;width:293.55375px"><div style="width:calc(100% - 25.784999999999997px);height:calc(100% - 12.892499999999998px);margin-left:12.892499999999998px;margin-top:6.446249999999999px;background-image:url(/static/images/2018/07/lime-1530894622923.png);background-size:contain;background-position:center center;background-repeat:no-repeat"></div></div></div></div></div></div></a><div style="position:absolute;left:-1px;top:-1px;height:calc(158.7301587301587% + 2px);width:calc(158.7301587301587% + 2px);transform:scale(0.6300000000000001);transform-origin:left top;border:solid 2px black;pointer-events:none"></div></div></div></div><div style="display:grid"><div style="position:relative;display:grid;grid-template-rows:auto 1fr;margin-bottom:12.892499999999998px"><div style="text-transform:uppercase;font-size:12.892499999999998px;letter-spacing:0.03em;line-height:1.5;padding-bottom:6.446249999999999px;padding-left:25.784999999999997px">Older</div><div style="position:relative;display:grid"><a class="hover-box no-underline no-hover gray-backer hover-extend" style="display:block;position:relative;width:612.8925px;padding-left:12.892499999999998px;padding-right:12.892499999999998px;margin-left:0;margin-right:0" href="/2018/07/31/neural-reinterpretations-of-movie-trailers.html"><div style="display:flex;flex-wrap:wrap"><div style="display:flex;width:587.1075px;font-size:12.892499999999998px;letter-spacing:0.03em;text-transform:uppercase;line-height:1.5;margin-left:0"><div style="width:293.55375px;padding:12.892499999999998px 12.892499999999998px 0px 12.892499999999998px"><div>Jul 03 2018</div></div><div style="width:293.55375px;padding:12.892499999999998px 12.892499999999998px 0px 12.892499999999998px"><div>Newsletter</div></div></div><div style="position:relative;width:587.1075px;padding:12.892499999999998px 0px"><div style="font-size:25.784999999999997px;line-height:1.25;padding:0px 12.892499999999998px;margin-top:-6.446249999999999px"><div style="padding-left:0">Neural reinterpretations of movie trailers</div></div><div style="padding-top:6.446249999999999px;position:relative"><div style="font-size:15.041249999999998px;line-height:1.5em;display:flex;flex-wrap:wrap;padding-left:0"><div style="padding:0px 12.892499999999998px;width:293.55375px"><div style="height:90.24749999999999px;overflow:hidden;display:-webkit-box;-webkit-line-clamp:4;hyphens:auto;-webkit-box-orient:vertical"><span>by <!-- -->Grant<!-- --> ◦ </span>
In his latest project, artist and coder Mario Klingemann uses a neural network to match archival movie footage with the content of recent movie trailers. He regularly posts the resulting “neural reinterpretations” on his Twitter. The results are technically impressive. They’re...</div><div style="overflow:hidden;width:100%;text-overflow:ellipsis;white-space:nowrap"><span class="display-link"><span>View<!-- --> <span style="text-transform:lowercase">Newsletter</span></span></span></div></div><div style="position:relative;width:293.55375px"><div style="width:calc(100% - 25.784999999999997px);height:calc(100% - 12.892499999999998px);margin-left:12.892499999999998px;margin-top:6.446249999999999px;background-image:url(/static/images/editor_uploads/2018-06-26-144942-Screen_Shot_2018_06_25_at_10_46_42_AM.png);background-size:contain;background-position:center center;background-repeat:no-repeat"></div></div></div></div></div></div></a><div style="position:absolute;left:-1px;top:-1px;height:calc(158.7301587301587% + 2px);width:calc(158.7301587301587% + 2px);transform:scale(0.6300000000000001);transform-origin:left top;border:solid 2px black;pointer-events:none"></div></div></div></div></div><div style="padding-bottom:25.784999999999997px;padding-top:25.784999999999997px" class="jsx-1135431938 jsx-2959859206"><div style="font-size:34.379999999999995px;line-height:1.25;padding:0px 12.892499999999998px 0px 12.892499999999998px;margin-bottom:12.892499999999998px;width:587.1075px;margin-left:0" class="jsx-1135431938 jsx-2959859206">About</div><div style="padding:0px 12.892499999999998px;margin-bottom:12.892499999999998px;width:587.1075px;margin-left:0;font-size:17.189999999999998px;line-height:1.5" class="jsx-1135431938 jsx-2959859206">Cloudera Fast Forward Labs is an applied machine learning research group. We help organizations recognize and develop new product and business opportunities through emerging technologies.<!-- --> </div><div style="padding:0px 12.892499999999998px;margin-bottom:12.892499999999998px;width:587.1075px;margin-left:0;font-size:17.189999999999998px;line-height:1.5" class="jsx-1135431938 jsx-2959859206"><a href="https://www.cloudera.com/products/fast-forward-labs-research.html" class="jsx-1135431938 jsx-2959859206">Learn more about working with us.</a></div></div></div><div class="jsx-1135431938 jsx-2959859206"><div style="position:relative" class="jsx-1135431938 jsx-2959859206"><div style="position:absolute;left:0;width:100%;height:2px;transform:scaleY(0.60165);transform-origin:center center;background:black;top:-1px"></div><div style="padding:12.892499999999998px;display:flex;justify-content:space-between;flex-wrap:wrap;font-size:17.189999999999998px;line-height:1.5" class="jsx-1135431938 jsx-2959859206"><div class="jsx-1135431938 jsx-2959859206"><a href="/" class="jsx-1135431938 jsx-2959859206">Blog</a></div><div style="display:flex;flex-wrap:wrap" class="jsx-1135431938 jsx-2959859206"><div style="margin-right:12.892499999999998px" class="jsx-1135431938 jsx-2959859206"><a href="https://www.cloudera.com/products/fast-forward-labs-research.html" class="jsx-1135431938 jsx-2959859206">Cloudera</a></div><div style="margin-right:12.892499999999998px" class="jsx-1135431938 jsx-2959859206"><a href="https://blog.fastforwardlabs.com/" class="jsx-1135431938 jsx-2959859206">AI Experiments</a></div><div class="jsx-1135431938 jsx-2959859206"><a href="https://twitter.com/fastforwardlabs" class="jsx-1135431938 jsx-2959859206">Twitter</a></div></div></div></div></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{}},"page":"/posts/2018-07-31-new-dynamics-for-topic-models","query":{},"buildId":"Ybc3fb3eGTaHFGC_lgzB6","nextExport":true}</script><script async="" id="__NEXT_PAGE__/posts/2018-07-31-new-dynamics-for-topic-models" src="/_next/static/Ybc3fb3eGTaHFGC_lgzB6/pages/posts/2018-07-31-new-dynamics-for-topic-models.js"></script><script async="" id="__NEXT_PAGE__/_app" src="/_next/static/Ybc3fb3eGTaHFGC_lgzB6/pages/_app.js"></script><script src="/_next/static/runtime/webpack-fdce77a122c11e06ae50.js" async=""></script><script src="/_next/static/chunks/commons.f77b50de979bfbbb280b.js" async=""></script><script src="/_next/static/runtime/main-5ab107747766f1b4e0bf.js" async=""></script></body></html>