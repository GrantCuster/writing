<!DOCTYPE html><html><head><link rel="preload" href="/static/fonts/Inter-Regular.woff2?v=3.5" as="font" type="font/woff2" crossorigin="*"/><link rel="preload" href="/static/fonts/Inter-Italic.woff2?v=3.5" as="font" type="font/woff2" crossorigin="*"/><link href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css" rel="stylesheet"/><meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1" class="next-head"/><meta charSet="utf-8" class="next-head"/><style class="next-head">.js-no-flash { display: none }</style><noscript class="jsx-4059783939 jsx-3344216300 next-head"><style>.js-no-flash { display: block }</style></noscript><link rel="icon" type="image/x-icon" href="static/images/favicon.png" class="jsx-1135431938 jsx-2959859206 next-head"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous" class="jsx-1135431938 jsx-2959859206 next-head"/><title class="jsx-1135431938 jsx-2959859206 next-head">Causality in machine learning - Cloudera Fast Forward</title><link rel="preload" href="/_next/static/Ybc3fb3eGTaHFGC_lgzB6/pages/posts/2019-02-28-causality-in-machine-learning.js" as="script"/><link rel="preload" href="/_next/static/Ybc3fb3eGTaHFGC_lgzB6/pages/_app.js" as="script"/><link rel="preload" href="/_next/static/runtime/webpack-fdce77a122c11e06ae50.js" as="script"/><link rel="preload" href="/_next/static/chunks/commons.f77b50de979bfbbb280b.js" as="script"/><link rel="preload" href="/_next/static/runtime/main-5ab107747766f1b4e0bf.js" as="script"/><style id="__jsx-4059783939">@font-face{font-family:'Inter';font-style:normal;font-weight:400;src:url('/static/fonts/Inter-Regular.woff2?v=3.5') format('woff2'), url('/static/fonts/Inter-Regular.woff?v=3.5') format('woff');}@font-face{font-family:'Inter';font-style:italic;font-weight:400;src:url('/static/fonts/Inter-Italic.woff2?v=3.5') format('woff2'), url('/static/fonts/Inter-Italic.woff?v=3.5') format('woff');}@font-face{font-family:'Inter';font-style:normal;font-weight:700;src:url('/static/fonts/Inter-Bold.woff2?v=3.5') format('woff2'), url('/static/fonts/Inter-Bold.woff?v=3.5') format('woff');}@font-face{font-family:'Inter';font-style:italic;font-weight:700;src:url('/static/fonts/Inter-BoldItalic.woff2?v=3.5') format('woff2'), url('/static/fonts/Inter-BoldItalic.woff?v=3.5') format('woff');}*{box-sizing:border-box;}html{font-family:'Inter',serif;font-size:18px;line-height:27px;text-rendering:optimizelegibility;font-feature-settings:'kern';font-kerning:normal;font-feature-settings:'ss02' 1;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;}pre{-webkit-font-smoothing:auto;-moz-osx-font-smoothing:auto;overflow-x:auto;font-family:SFMono-Regular,Consolas,Liberation Mono,Menlo, Monaco,Courier New,monospace;}body{margin:0;overflow-x:hidden;}a{color:inherit;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:opacity 0.025s linear;transition:opacity 0.025s linear;}a:hover{opacity:0.75;}a.no-hover:hover{opacity:1;}.hover_box_overlay{opacity:0;-webkit-transition:opacity 0.025s linear;transition:opacity 0.025s linear;}.hover_box:hover .hover_box_overlay{opacity:1;}a.gray-backer{-webkit-transition:background 0.05s linear;transition:background 0.05s linear;}a.gray-backer:hover{background:#f3f3f3;}button:focus{outline:#999 auto 3px;}</style><style id="__jsx-3344216300">html{font-size:17.189999999999998px;line-height:25.784999999999997px;}a,.display-link{background-image:linear-gradient( to right, black 100%, transparent 0% );background-position:0em calc(1.07em);background-repeat:repeat-x;background-size:1em 0.07em;}a.no-underline{background-image:none;}a.no-hover{background-image:none;}a.no-hover:hover{background-image:none;opacity:1;}</style><style id="__jsx-2959859206">h1,h2,h3,h4,h5,h6{font-weight:400;font-style:normal;margin:0;}h1{font-size:51.56999999999999px;line-height:1.25;}h2{font-size:34.379999999999995px;line-height:1.25;padding-top:25.784999999999997px;margin-bottom:25.784999999999997px;}h3{font-size:25.784999999999997px;line-height:1.25;padding-top:25.784999999999997px;margin-bottom:25.784999999999997px;}h4{font-size:21.487499999999997px;line-height:1.25;padding-top:0px;margin-bottom:25.784999999999997px;}h5{font-size:12.892499999999998px;line-height:1.4375;margin-bottom:12.892499999999998px;padding-bottom:12.892499999999998px;margin-top:-12.892499999999998px;}p{margin:0 0 25.784999999999997px 0;}ol,ul{margin:0 0 25.784999999999997px 0;padding-left:25.784999999999997px;}blockquote{margin:0 0 25.784999999999997px 25.784999999999997px;}.html-video-holder{margin:0 0 25.784999999999997px 0;}video{max-width:100%;}code{background:#eaeaea;padding-right:3px;padding-left:3px;font-size:0.975em;word-break:break-word;}</style><style id="__jsx-1135431938">code[class*='language-'],pre[class*='language-']{color:black;background:none;font-family:Consolas,Monaco,'Andale Mono','Ubuntu Mono', monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;}pre[class*='language-']::-moz-selection,pre[class*='language-']::-moz-selection,code[class*='language-']::-moz-selection,code[class*='language-']::-moz-selection{text-shadow:none;}pre[class*='language-']::selection,pre[class*='language-']::selection,code[class*='language-']::selection,code[class*='language-']::selection{text-shadow:none;}@media print{code[class*='language-'],pre[class*='language-']{text-shadow:none;}}:not(pre)>code[class*='language-']{white-space:normal;}.token.comment,.token.prolog,.token.doctype,.token.cdata{color:slategray;}.token.punctuation{color:#999;}.namespace{opacity:0.7;}.token.property,.token.tag,.token.boolean,.token.number,.token.constant,.token.symbol,.token.deleted{color:#905;}.token.selector,.token.attr-name,.token.string,.token.char,.token.builtin,.token.inserted{color:#690;}.token.operator,.token.entity,.token.url,.language-css .token.string,.style .token.string{color:#9a6e3a;}.token.atrule,.token.attr-value,.token.keyword{color:#07a;}.token.function,.token.class-name{color:#dd4a68;}.token.regex,.token.important,.token.variable{color:#e90;}.token.important,.token.bold{font-weight:bold;}.token.italic{font-style:italic;}.token.entity{cursor:help;}</style></head><body><div id="__next"><div class="jsx-4059783939 jsx-3344216300 js-no-flash"><div style="padding-bottom:12.892499999999998px"><div style="position:relative"><div style="position:relative;padding:6.446249999999999px 12.892499999999998px 6.446249999999999px 12.892499999999998px;background-image:url(&quot;/static/images/dataline.png&quot;)"><div style="display:flex;justify-content:space-between"><div style="display:flex;align-items:center;height:25.784999999999997px;padding-top:1px"><a href="https://www.cloudera.com/products/fast-forward-labs-research.html" style="display:block;line-height:0" class="no-underline no-hover"><img style="height:12.892499999999998px" src="/static/images/cloudera.png"/></a></div><div style="display:flex;align-items:center;padding-top:1px;font-size:17.189999999999998px;line-height:1.5"><a class="no-underline" href="https://www.cloudera.com/products/fast-forward-labs-research.html" style="color:#333e47;font-size:12.892499999999998px;line-height:1.5">About Us →</a></div></div><div style="position:absolute;left:0;width:100%;height:2px;transform:scaleY(0.60165);transform-origin:center center;background:rgba(0,0,0,0.125);bottom:-1px"></div></div><div style="padding:12.892499999999998px 12.892499999999998px 12.892499999999998px 12.892499999999998px;display:flex;justify-content:space-between;font-size:17.189999999999998px;line-height:1.5"><div style="display:flex;align-items:center"><a class="no-hover no-underline" style="display:flex;align-items:center" href="/"><img style="height:18.75272727272727px;width:18.75272727272727px;margin-right:9.669374999999999px;position:relative;top:-0.5860227272727272px" src="/static/images/ff.png"/><div>Fast Forward Labs </div></a></div><div style="display:flex;align-items:center;height:25.784999999999997px"></div><div style="display:flex"><div style="margin-right:12.892499999999998px"><a href="/">Blog</a></div><div><a href="https://experiments.fastforwardlabs.com">AI Experiments</a></div></div></div><div style="position:absolute;left:0;width:100%;height:2px;transform:scaleY(0.60165);transform-origin:center center;background:black;bottom:-1px"></div></div></div><div class="jsx-1135431938 jsx-2959859206"><div style="position:relative" class="jsx-1135431938 jsx-2959859206"><div style="padding-left:6.446249999999999px;padding-right:6.446249999999999px;padding-top:25.784999999999997px" class="jsx-1135431938 jsx-2959859206"><div class="jsx-1135431938 jsx-2959859206"><div style="display:flex;margin-bottom:12.892499999999998px;width:587.1075px;margin-left:0" class="jsx-1135431938 jsx-2959859206"><div style="width:293.55375px;padding:0px 12.892499999999998px;position:relative;font-size:12.892499999999998px;letter-spacing:0.03em;text-transform:uppercase;line-height:1" class="jsx-1135431938 jsx-2959859206">Feb 05 2019</div><div style="width:293.55375px;padding:0px 12.892499999999998px;position:relative;font-size:12.892499999999998px;letter-spacing:0.03em;text-transform:uppercase;line-height:1" class="jsx-1135431938 jsx-2959859206">newsletter</div></div><div style="margin-bottom:0" class="jsx-1135431938 jsx-2959859206"><div style="font-size:42.974999999999994px;line-height:1.25;padding:0px 12.892499999999998px;width:587.1075px;margin-left:0" class="jsx-1135431938 jsx-2959859206">Causality in machine learning</div></div><div style="display:flex;flex-wrap:wrap;width:587.1075px;margin-left:0" class="jsx-1135431938 jsx-2959859206"><div style="padding:12.892499999999998px 12.892499999999998px 0px 12.892499999999998px;width:587.1075px" class="jsx-1135431938 jsx-2959859206"><div class="jsx-1135431938 jsx-2959859206">by<!-- --> <a href="https://twitter.com/shendrickson16" class="jsx-1135431938 jsx-2959859206">Seth</a></div></div><div style="width:587.1075px;padding:25.784999999999997px 12.892499999999998px 25.784999999999997px 12.892499999999998px" class="jsx-1135431938 jsx-2959859206"><p><a href="https://en.wikipedia.org/wiki/Judea_Pearl">Judea Pearl</a>, the inventor of <a href="https://en.wikipedia.org/wiki/Bayesian_network">Bayesian networks</a>, recently published a book called <em><a href="https://www.amazon.com/dp/B075CR9QBJ/">The Book of Why: The New Science of Cause and Effect</a></em>. The book covers a great many things, including a detailed history of how the fields of causality and statistics have long been at odds, Pearl&#x27;s own <a href="https://www.inference.vc/untitled/"><em>do-calculus</em></a> framework for teasing causal inferences from observational data, and why (in Pearl&#x27;s view) the future of AI depends on causality. </p><p><div style="position:relative"><img src="/static/images/editor_uploads/2019-03-12-191909-correlation.png" style="display:block;margin:0;width:100%"/></div></p><h5>Source: <a href="https://xkcd.com/552/">&quot;Correlation&quot; by Randall Munroe at XKCD</a></h5><p>One of the key points in Pearl&#x27;s book is that observational data - data collected from real world systems - on its own, can only possibly convey associations between variables. To glean which variables in the data act as causes, and which are effects of those causes, we need something more. The implications are profound. A pharmaceutical company cannot ever tell if a particular drug is an effective treatment for a disease simply by observing the outcomes of patients who have taken that drug. It is impossible for scientists to prove that smoking causes lung cancer from observing outcomes of smokers and non-smokers. And yet, these are both things that we as a society have the capability to do today.</p><p>The traditional method for proving cause and effect is called a <a href="https://en.wikipedia.org/wiki/Randomized_controlled_trial">randomized controlled trial</a>. In a randomized controlled trial, you randomly assign some test subjects to a treatment group and some to a control group. In the case of proving the effectiveness of a drug, patients are randomly assigned to receive the drug or not. By doing this, you can guarantee that the two groups are the same in every possible way, except for the treatment. If you then observe that the outcomes of one group are better than another, you can conclude that the treatment causes the improved outcome.</p><p>But randomized controlled trials are expensive, slow, and oftentimes impossible. You cannot ethically force a group of patients to smoke for a lifetime simply for the sake of proving that smoking causes cancer. And indeed, this is precisely the dilemma that made it extremely difficult to prove that smoking causes cancer, a topic Pearl covers in exquisite detail in his book. On top of that, observational data is cheap and plentiful. Is there truly no way to tease causality from observational data?</p><p>In a <a href="https://www.youtube.com/watch?v=ynVr_zzUXtw">recent panel on causality</a> from the Machine Learning Summer School in South Africa, Columbia University professor <a href="http://www.cs.columbia.edu/~blei/">David Blei</a> explained that this conundrum is precisely what has motivated him to pursue causality in his research.</p><blockquote><p>&quot;When you sit down and read all the books about causal inference and all the papers about it, it&#x27;s very theoretical but there&#x27;s one message that you get, from the historical perspective anyway, which is that causal inference from observational data is impossible . . . To me that seemed silly, that with, say you&#x27;re a hospital and you have 250 million electronic health records of what medicines people received and what happened to those people. It seemed silly to say that it is impossible to learn, say that Advil helps headaches.&quot;</p></blockquote><p>There are many ways in which causal understanding could improve the fields of machine learning and AI, and the ability to reliably infer causation from observational data is a hot topic. Judea Pearl&#x27;s do-calculus is primarily a framework for doing just that. Under the right conditions and with some assumptions, causality can be inferred from purely observational data.</p><p>A machine learning model that captures causal relationships of data is one way to ensure that the model will generalize to new settings, one of the most difficult aspects of machine learning. A model that associates the rising of the sun with the crow of a rooster may be able to adequately predict when the sun will rise. If the rooster has just crowed, the sun will rise shortly thereafter. This model will not, however, generalize to situations where there is no rooster. It would never predict that the sun will rise because it has never observed such a data point. However, if the model captured the causal relationships between the two, that the sun being about to rise causes the rooster&#x27;s crow, it would be obvious that the sun will rise even without the rooster.</p><p>Causality is also tightly related to fairness in machine learning, <a href="https://blog.fastforwardlabs.com/newsletters/2019-02-06-client.html">a topic we care deeply about</a>. In <em>The Book of Why</em>, Pearl discusses the &quot;Berkeley admissions paradox,&quot; the story of one statistician&#x27;s attempt in the 1970s to detect potential discrimination against admitting women at UC Berkeley. Pearl discusses how traditional statistics combined only with observational data can lead to competing conclusions. It is possible to conclude that the university discriminated against women or that they discriminated in favor of women, depending on how you slice the data. Only using the language of causality can we draw correct conclusions.</p><p>The role of causality in AI and machine learning is a controversial topic, and Pearl has no problems stoking that controversy in his book. Regardless, <em>The Book of Why</em> has helped revive the topic of causality in the ML and AI communities. In the recent machine learning summer school in South Africa, there were multiple sessions on causality. At the recent <a href="https://fatconference.org/2019/">Fairness, Accountability, and Trust</a> conference there were multiple discussions devoted to causality. <a href="https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/">Textbooks on causality</a> are being published and <a href="https://www.glassdoor.com/job-listing/data-scientist-causal-inference-and-experimental-design-marketing-science-rd-facebook-JV_IC1150505_KO0,76_KE77,85.htm?jl=3014078256&amp;ctt=1549578150049">multiple</a> <a href="https://www.glassdoor.com/job-listing/researcher-causality-and-machine-learning-microsoft-JV_IC1150499_KO0,41_KE42,51.htm?jl=3087412884&amp;ctt=1549578042811">jobs</a> asking for causal inference are popping up. Though the immediate future of causality in machine learning is likely (still) limited to randomized controlled trials like A/B testing, the potential to draw causal conclusions from near-unlimited quantities of observational data is too great to ignore. Finally, Pearl argues that cause and effect are the key mechanisms through which humans process the complex world around them, and that we can never reach true <a href="https://en.wikipedia.org/wiki/Artificial_general_intelligence">artificial general intelligence</a> without equipping machines with notions of cause and effect.
</p><div style="display:none;justify-content:center;padding:12.892499999999998px" class="jsx-1135431938 jsx-2959859206"><img style="height:18.75272727272727px;width:18.75272727272727px;position:relative;display:block" src="/static/images/ff.png" class="jsx-1135431938 jsx-2959859206"/></div></div></div></div><div style="position:relative;display:block;width:612.8924999999999px;grid-template-columns:repeat(2, 1fr);margin-left:-12.892499999999998px;margin-right:-12.892499999999998px"><div style="display:grid"><div style="position:relative;display:grid;grid-template-rows:auto 1fr;margin-bottom:12.892499999999998px"><div style="text-transform:uppercase;font-size:12.892499999999998px;letter-spacing:0.03em;line-height:1.5;padding-bottom:6.446249999999999px;padding-left:25.784999999999997px">Newer</div><div style="position:relative;display:grid"><a class="hover-box no-underline no-hover gray-backer hover-extend" style="display:block;position:relative;width:612.8925px;padding-left:12.892499999999998px;padding-right:12.892499999999998px;margin-left:0;margin-right:0" href="/2019/03/20/learning-with-limited-labeled-data.html"><div style="display:flex;flex-wrap:wrap"><div style="display:flex;width:587.1075px;font-size:12.892499999999998px;letter-spacing:0.03em;text-transform:uppercase;line-height:1.5;margin-left:0"><div style="width:293.55375px;padding:12.892499999999998px 12.892499999999998px 0px 12.892499999999998px"><div>Mar 04 2019</div></div><div style="width:293.55375px;padding:12.892499999999998px 12.892499999999998px 0px 12.892499999999998px"><div>post</div></div></div><div style="position:relative;width:587.1075px;padding:12.892499999999998px 0px"><div style="font-size:25.784999999999997px;line-height:1.25;padding:0px 12.892499999999998px;margin-top:-6.446249999999999px"><div style="padding-left:0">Learning with Limited Labeled Data</div></div><div style="padding-top:6.446249999999999px;position:relative"><div style="font-size:15.041249999999998px;line-height:1.5em;display:flex;flex-wrap:wrap;padding-left:0"><div style="padding:0px 12.892499999999998px;width:293.55375px"><div style="height:90.24749999999999px;overflow:hidden;display:-webkit-box;-webkit-line-clamp:4;hyphens:auto;-webkit-box-orient:vertical"><span>by <!-- -->Shioulin and Nisha<!-- --> ◦ </span>
In recent years, machine learning technologies - especially deep learning - have made breakthroughs which have turned science fiction into reality. Autonomous cars are almost possible, and machines can comprehend language. These technical advances are unprecedented, but they...</div><div style="overflow:hidden;width:100%;text-overflow:ellipsis;white-space:nowrap"><span class="display-link"><span>View<!-- --> <span style="text-transform:lowercase">post</span></span></span></div></div><div style="position:relative;width:293.55375px"><div style="width:calc(100% - 25.784999999999997px);height:calc(100% - 12.892499999999998px);margin-left:12.892499999999998px;margin-top:6.446249999999999px;background-image:url(/static/images/editor_uploads/2019-03-21-201701-AL_loop.png);background-size:contain;background-position:center center;background-repeat:no-repeat"></div></div></div></div></div></div></a><div style="position:absolute;left:-1px;top:-1px;height:calc(158.7301587301587% + 2px);width:calc(158.7301587301587% + 2px);transform:scale(0.6300000000000001);transform-origin:left top;border:solid 2px black;pointer-events:none"></div></div></div></div><div style="display:grid"><div style="position:relative;display:grid;grid-template-rows:auto 1fr;margin-bottom:12.892499999999998px"><div style="text-transform:uppercase;font-size:12.892499999999998px;letter-spacing:0.03em;line-height:1.5;padding-bottom:6.446249999999999px;padding-left:25.784999999999997px">Older</div><div style="position:relative;display:grid"><a class="hover-box no-underline no-hover gray-backer hover-extend" style="display:block;position:relative;width:612.8925px;padding-left:12.892499999999998px;padding-right:12.892499999999998px;margin-left:0;margin-right:0" href="/2019/01/29/making-an-interactive-umap-visualization-of-the-mnist-data-set.html"><div style="display:flex;flex-wrap:wrap"><div style="display:flex;width:587.1075px;font-size:12.892499999999998px;letter-spacing:0.03em;text-transform:uppercase;line-height:1.5;margin-left:0"><div style="width:293.55375px;padding:12.892499999999998px 12.892499999999998px 0px 12.892499999999998px"><div>Jan 03 2019</div></div><div style="width:293.55375px;padding:12.892499999999998px 12.892499999999998px 0px 12.892499999999998px"><div>newsletter</div></div></div><div style="position:relative;width:587.1075px;padding:12.892499999999998px 0px"><div style="font-size:25.784999999999997px;line-height:1.25;padding:0px 12.892499999999998px;margin-top:-6.446249999999999px"><div style="padding-left:0">Making an interactive UMAP visualization of the MNIST data set</div></div><div style="padding-top:6.446249999999999px;position:relative"><div style="font-size:15.041249999999998px;line-height:1.5em;display:flex;flex-wrap:wrap;padding-left:0"><div style="padding:0px 12.892499999999998px;width:293.55375px"><div style="height:90.24749999999999px;overflow:hidden;display:-webkit-box;-webkit-line-clamp:4;hyphens:auto;-webkit-box-orient:vertical"><span>by <!-- -->Grant<!-- --> ◦ </span>
A GIF of zooming into the MNIST visualization

UMAP explorer: an interactive visualization of the MNIST data set

We&#x27;re in the middle of work on our next report, Learning with Limited Labeled Data, and the accompanying prototype. For the prototype&#x27;s front-end we wanted to be...</div><div style="overflow:hidden;width:100%;text-overflow:ellipsis;white-space:nowrap"><span class="display-link"><span>View<!-- --> <span style="text-transform:lowercase">newsletter</span></span></span></div></div><div style="position:relative;width:293.55375px"><div style="width:calc(100% - 25.784999999999997px);height:calc(100% - 12.892499999999998px);margin-left:12.892499999999998px;margin-top:6.446249999999999px;background-image:url(http://feed.grantcuster.com/static/images/feed/umap_zoom-1547839236092.gif);background-size:contain;background-position:center center;background-repeat:no-repeat"></div></div></div></div></div></div></a><div style="position:absolute;left:-1px;top:-1px;height:calc(158.7301587301587% + 2px);width:calc(158.7301587301587% + 2px);transform:scale(0.6300000000000001);transform-origin:left top;border:solid 2px black;pointer-events:none"></div></div></div></div></div><div style="padding-bottom:25.784999999999997px;padding-top:25.784999999999997px" class="jsx-1135431938 jsx-2959859206"><div style="font-size:34.379999999999995px;line-height:1.25;padding:0px 12.892499999999998px 0px 12.892499999999998px;margin-bottom:12.892499999999998px;width:587.1075px;margin-left:0" class="jsx-1135431938 jsx-2959859206">About</div><div style="padding:0px 12.892499999999998px;margin-bottom:12.892499999999998px;width:587.1075px;margin-left:0;font-size:17.189999999999998px;line-height:1.5" class="jsx-1135431938 jsx-2959859206">Cloudera Fast Forward Labs is an applied machine learning research group. We help organizations recognize and develop new product and business opportunities through emerging technologies.<!-- --> </div><div style="padding:0px 12.892499999999998px;margin-bottom:12.892499999999998px;width:587.1075px;margin-left:0;font-size:17.189999999999998px;line-height:1.5" class="jsx-1135431938 jsx-2959859206"><a href="https://www.cloudera.com/products/fast-forward-labs-research.html" class="jsx-1135431938 jsx-2959859206">Learn more about working with us.</a></div></div></div><div class="jsx-1135431938 jsx-2959859206"><div style="position:relative" class="jsx-1135431938 jsx-2959859206"><div style="position:absolute;left:0;width:100%;height:2px;transform:scaleY(0.60165);transform-origin:center center;background:black;top:-1px"></div><div style="padding:12.892499999999998px;display:flex;justify-content:space-between;flex-wrap:wrap;font-size:17.189999999999998px;line-height:1.5" class="jsx-1135431938 jsx-2959859206"><div class="jsx-1135431938 jsx-2959859206"><a href="/" class="jsx-1135431938 jsx-2959859206">Blog</a></div><div style="display:flex;flex-wrap:wrap" class="jsx-1135431938 jsx-2959859206"><div style="margin-right:12.892499999999998px" class="jsx-1135431938 jsx-2959859206"><a href="https://www.cloudera.com/products/fast-forward-labs-research.html" class="jsx-1135431938 jsx-2959859206">Cloudera</a></div><div style="margin-right:12.892499999999998px" class="jsx-1135431938 jsx-2959859206"><a href="https://blog.fastforwardlabs.com/" class="jsx-1135431938 jsx-2959859206">AI Experiments</a></div><div class="jsx-1135431938 jsx-2959859206"><a href="https://twitter.com/fastforwardlabs" class="jsx-1135431938 jsx-2959859206">Twitter</a></div></div></div></div></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{}},"page":"/posts/2019-02-28-causality-in-machine-learning","query":{},"buildId":"Ybc3fb3eGTaHFGC_lgzB6","nextExport":true}</script><script async="" id="__NEXT_PAGE__/posts/2019-02-28-causality-in-machine-learning" src="/_next/static/Ybc3fb3eGTaHFGC_lgzB6/pages/posts/2019-02-28-causality-in-machine-learning.js"></script><script async="" id="__NEXT_PAGE__/_app" src="/_next/static/Ybc3fb3eGTaHFGC_lgzB6/pages/_app.js"></script><script src="/_next/static/runtime/webpack-fdce77a122c11e06ae50.js" async=""></script><script src="/_next/static/chunks/commons.f77b50de979bfbbb280b.js" async=""></script><script src="/_next/static/runtime/main-5ab107747766f1b4e0bf.js" async=""></script></body></html>